{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to MkDocs","text":"<p>For full documentation visit mkdocs.org.</p>"},{"location":"#commands","title":"Commands","text":"<ul> <li><code>mkdocs new [dir-name]</code> - Create a new project.</li> <li><code>mkdocs serve</code> - Start the live-reloading docs server.</li> <li><code>mkdocs build</code> - Build the documentation site.</li> <li><code>mkdocs -h</code> - Print help message and exit.</li> </ul>"},{"location":"#project-layout","title":"Project layout","text":"<pre><code>mkdocs.yml    # The configuration file.\ndocs/\n    index.md  # The documentation homepage.\n    ...       # Other markdown pages, images and other files.\n</code></pre>"},{"location":"modeloCapa/","title":"modeloCapa","text":"<p>Usando pandoc com xelatex</p>"},{"location":"modeloCapa/#titulo","title":"T\u00edtulo","text":"<p>\\vspace{10cm}</p> <p>Autor: Wildemberg Sales da Silva Junior</p> <p>Matr\u00edcula: 202017503</p> <p>Data: 19/11/2024</p> <p>Institui\u00e7\u00e3o/Universidade: Universidade de Bras\u00edlia(UnB)</p> <p>Disciplina: Intelig\u00eancia Artificial - FGA0221</p> <p>\\newpage</p>"},{"location":"modeloCapa/#resumo","title":"Resumo","text":"<p>Este artigo oferece uma vis\u00e3o abrangente sobre ...</p>"},{"location":"modeloCapa/#visao-geral","title":"Vis\u00e3o Geral","text":"<p>\\newpage</p>"},{"location":"portifolios/portifolio1/","title":"Intelig\u00eancia Artificial em Aspectos Gerais e uma Vis\u00e3o Macro sobre Agentes Inteligentes","text":"<p>Autor: Wildemberg Sales da Silva Junior</p> <p>Matr\u00edcula: 202017503</p> <p>Data: 19/11/2024</p> <p>Institui\u00e7\u00e3o/Universidade: Universidade de Bras\u00edlia(UnB)</p> <p>Disciplina: Intelig\u00eancia Artificial - FGA0221</p>"},{"location":"portifolios/portifolio1/#resumo","title":"Resumo","text":"<p>Este artigo oferece uma vis\u00e3o abrangente sobre a Intelig\u00eancia Artificial (IA), abordando sua origem, os fundamentos que definem o modelo padr\u00e3o, as caracter\u00edsticas essenciais para a defini\u00e7\u00e3o de intelig\u00eancia e IA, al\u00e9m da concep\u00e7\u00e3o de agentes inteligentes. Foram explorados os modelos e conceitos cl\u00e1ssicos do pensamento, com o objetivo de compreender como as IAs devem agir, investigando as caracter\u00edsticas do pensamento humano e racional. Aprofundamos a an\u00e1lise para definir o que s\u00e3o agentes inteligentes, suas principais caracter\u00edsticas e seu papel dentro dos ambientes em que atuam, destacando como as propriedades do ambiente podem influenciar o comportamento de um agente. Por fim, discutimos alguns dos tipos de agentes existentes, suas atua\u00e7\u00f5es e aplica\u00e7\u00f5es.</p>"},{"location":"portifolios/portifolio1/#introducao","title":"Introdu\u00e7\u00e3o","text":"<p>A capacidade humana de evolu\u00e7\u00e3o sempre foi alta, e agora com a era da intelig\u00eancia artificial (IA), essa capacidade tende a ser mais alta ainda, transformando sonhos em realidade, ideias em produtos, e tarefas que demorariam anos para serem realizadas, em tarefas de minutos. </p> <p>Um fator importante quando falamos do mundo atual e do uso da IA, \u00e9 que modelos de IA j\u00e1 existem a muito mais tempo do que parece, isso se pensarmos que o primeiro modelo de IA foi o modelo de neur\u00f4nios criado por Warren McCulloch e Walter Pitts em 1943. Entretanto, o uso de modelos de Large Language Model(LLM) se popularizou de uma forma exponencial nos \u00faltimos anos, e devido a isso, profissionais de diversas \u00e1reas come\u00e7aram a ter o prazer e o poder dessas ferramentas, tornando o uso da IA mais comum no cotidiano.</p> <p>Nos dias de hoje o entendimento sobre o que \u00e9 IA e suas ramifica\u00e7\u00f5es \u00e9 um fator importante e diferencial para diversas \u00e1reas, suas aplica\u00e7\u00f5es na forma correta podem mudar o rumo de diversos setores, entender sua origem cria bases s\u00f3lidas e geram oportunidades de novas pesquisas e entendimentos sobre suas aplica\u00e7\u00f5es, al\u00e9m de que entender seus limites, riscos e benef\u00edcios proporciona um entendimento profundo sobre como usar suas ferramentas e agregar valor nas utiliza\u00e7\u00f5es do dia a dia.</p> <p>Neste artigo abordaremos uma vis\u00e3o geral do que \u00e9 a Intelig\u00eancia Artifical, desde sua origem, como a definimos, suas utiliza\u00e7\u00f5es no cen\u00e1rio atual, e seu impacto no mundo, trazendo diversos exemplos reais do seu uso, e tamb\u00e9m vis\u00f5es abstratas dos assuntos para um melhor entendimento da informa\u00e7\u00e3o.</p>"},{"location":"portifolios/portifolio1/#fundamentos-da-inteligencia-e-da-ia","title":"Fundamentos da Intelig\u00eancia e da IA","text":""},{"location":"portifolios/portifolio1/#o-que-e-inteligencia","title":"O que \u00e9 Intelig\u00eancia?","text":"<p>Antes de entender o que \u00e9 intelig\u00eancia artificial, devemos entender o fundamento do que \u00e9 a intelig\u00eancia.  </p> <p>Durante anos diversos autores tentam definir o que \u00e9 intelig\u00eancia, muitos relacionam com o ato de escolher o melhor, seja caminho ou outro tipo de escolha, outros relacionam com o ato de raciocinar sobre assuntos e compreender eles, alguns ligam a ideia de intelig\u00eancia a capacidade de aprender e ou se adaptar. Se observamos as defini\u00e7\u00f5es propostas, vemos que muitas fazem sentidos, e que muitas s\u00e3o realmente a defini\u00e7\u00e3o do que \u00e9 a intelig\u00eancia, pois intelig\u00eancia \u00e9 algo muito abstrato para ter somente uma defini\u00e7\u00e3o. Se buscarmos um pouco mais a fundo o significado de intelig\u00eancia e trouxermos sua etimologia para o nosso estudo, vemos que a palavra intelig\u00eancia vem do latim intellectus de intelligere que significa inteligir, entender, compreender. Se compararmos a defini\u00e7\u00e3o da palavra vinda do latim, com algumas ideias propostas por autores, vemos que todas as defini\u00e7\u00f5es realmente se encaixam.  </p> <p>Proponho que voc\u00ea leitor tamb\u00e9m pense um pouco mais sobre esse assunto e que tente definir o que \u00e9 a intelig\u00eancia para si, esta abordagem pode te trazer um asptecto mais profundo de entendimento do que iremos discutir a seguir.</p>"},{"location":"portifolios/portifolio1/#o-que-e-a-inteligencia-artificial","title":"O que \u00e9 a Intelig\u00eancia Artificial?","text":"<p>Agora que temos uma vis\u00e3o mais ampla do que \u00e9 a intelig\u00eancia, como podemos definir o que \u00e9 IA?</p> <p>Para responder essa pergunta, podemos ver algumas das defini\u00e7\u00f5es impostas por grandes nomes do setor tecnol\u00f3gico:</p> <p>Intelig\u00eancia artificial, ou IA, \u00e9 uma tecnologia que permite que computadores e m\u00e1quinas simulem a capacidade de resolu\u00e7\u00e3o de problemas e a intelig\u00eancia humana. - (IBM)</p> <p>O campo da intelig\u00eancia artificial procura n\u00e3o apenas entender, mas tamb\u00e9m construir entidades inteligentes \u2013 m\u00e1quinas que pode calcular como agir de forma eficaz e segura em uma ampla variedade de novas situa\u00e7\u00f5es. - (Russell e Norving).</p> <p>A intelig\u00eancia artificial limitada, por vezes denominada \"IA fraca\", refere-se \u00e0 capacidade de um sistema inform\u00e1tico efetuar uma tarefa de \u00e2mbito limitado melhor do que um ser humano. A intelig\u00eancia artificial geral, por vezes denominada \"IA forte\" ou \"IA de n\u00edvel humano\", refere-se \u00e0 capacidade de um sistema inform\u00e1tico de superar os humanos em tarefas intelectuais. \u00c9 o tipo de IA que se v\u00ea nos filmes em que os robots desenvolvem pensamentos conscientes e agem de acordo com motiva\u00e7\u00f5es pr\u00f3prias. - (Microsoft)</p> <p>A partir das frases acima, pode-se notar que muitas vezes a IA \u00e9 relacionada com o pensar humano, vemos at\u00e9 uma compara\u00e7\u00e3o com o filme \"I, Robot\" 2004, que mostra a evolu\u00e7\u00e3o do mundo e o desenvolvimento de modelos de IA para servir os humanos, e quando uma IA se torna realmente capaz de pensar e opinar sobre diversos aspectos, ela come\u00e7a a parecer uma amea\u00e7a.  </p> <p>Mas ent\u00e3o entra a pergunta, supondo que o foco da evolu\u00e7\u00e3o das IA's seja ter uma \"intelig\u00eancia\" humana, o acontecimento disso seria bom ou ruim? O fato dela poder decidir sozinha sem interfer\u00eancia humana, o ato de pensar e raciocinar, traria benef\u00edcios ou malef\u00edcios ao ser humano? S\u00e3o quest\u00f5es a se pensar veja bem, o fator de poder perder o controle sobre elas pode trazer malef\u00edcios para a humanidade, mas em contra partida, o ato de pensar sozinha e tomar decis\u00f5es sozinhas pode resolver grandes problemas atuais e futuros, mas de qualquer forma, s\u00e3o perguntas que podem mudar suas opini\u00f5es sobre o uso da IA e devem ser pensadas com calma.  </p> <p>Voltando ao t\u00f3pico do assunto que engloba uma defini\u00e7\u00e3o para o que \u00e9 intelig\u00eancia artificial, podemos considerar que \u00e9 o ato de uma m\u00e1quina conseguir um n\u00edvel de \"intelig\u00eancia\" similar a de um humano, com a capacidade de raciocinar, calcular, aprender, e decidir sobre as escolhes impostas.</p>"},{"location":"portifolios/portifolio1/#origem-da-ia","title":"Origem da IA","text":"<p>Uma das grandes perguntas que v\u00e1rios estudantes iniciantes fazem \u00e9: \"Quem inventou a IA?\". Para saber sobre a origem da IA \u00e9 importante ter em mente que n\u00e3o foi uma pessoa espec\u00edfica, ou uma s\u00f3 teoria que gerou a IA, e sim um conjunto de pesquisas e pesquisadores que ao longo do tempo formularam diversos experimentos e teorias sobre esse assunto formando a IA como ela \u00e9 hoje.  </p> <p>Podemos trazer aqui duas das principais pesquisas que iniciaram as grandes pesquisas relacionadas a IA, dentre essas duas est\u00e3o o Teste de Turing, criado por Alan Turing, que era voltada a um teste em que uma m\u00e1quina tinha que se passar por um humano em uma conversa escrita com uma pessoa real, caso a pessoa que estivesse conversando com a m\u00e1quina n\u00e3o conseguisse diferenciar ela de uma pessoa real, a m\u00e1quina ganhava o teste. Outra grande pesquisa que influenciou os estudos na \u00e1rea de IA foi o Modelo de Neur\u00f4nios de Warren McCulloch e Walter Pitts (1943), onde esse modelo trazia a ideia de que cada neur\u00f4nio poderia ser caracterizado como \"ligado\" ou \"desligado\", e que o neur\u00f4nio passa do estado \"desligado\" para o \"ligado\" ap\u00f3s um grande estimulo de neur\u00f4nios vizinhos, trazendo um aspecto em que as redes de estivessem adequadamente definidas, poderiam ter a capacidade de aprender.  </p> <p>Algo importante que deve ser ressaltado \u00e9 que para o entendimento que temos hoje em dia sobre IA, diversas \u00e1reas se juntaram a pesquisa para poder trazer diferentes vis\u00f5es em aspectos matem\u00e1ticos e de mundo real, algumas das \u00e1reas que impulsionaram o desenvolvimento da IA s\u00e3o: Filosofia, Matem\u00e1tica, Economia, Neuroci\u00eancia, Psicologia, Engenharia da computa\u00e7\u00e3o, Teoria de controle e Cibern\u00e9tica, Lingu\u00edstica, dentre v\u00e1rias outras.</p>"},{"location":"portifolios/portifolio1/#modelos-e-conceitos-classicos","title":"Modelos e Conceitos Cl\u00e1ssicos","text":"<p>Quando pensamos no processo de como uma IA deve agir, devemos entender como ela pensa e age de acordo com as situa\u00e7\u00f5es em que \u00e9 exposta, com isso, nesse t\u00f3pico abordarems dois modelos importantes para entender a modelagem do pensamento das IA's.</p>"},{"location":"portifolios/portifolio1/#pensando-de-forma-humana-modelagem-cognitiva","title":"Pensando de Forma Humana (Modelagem Cognitiva)","text":"<p>Para o pensamento de forma humana, podemos entender ele como a vis\u00e3o de diferentes execu\u00e7\u00f5es de a\u00e7\u00f5es com um mesmo objetivo, mas n\u00e3o somente com o foco de resolver o problema, e sim com uma vis\u00e3o de comparar as sequ\u00eancias, o tempo e as a\u00e7\u00f5es executadas com as dos humanos, com o foco de descobrir o melhor jeito para ser feito. Se pegarmos uma ideia do que \u00e9 o modelo cognitivo conseguimos separar em quatro etapas sequenciais: Situa\u00e7\u00e3o, Pensamento, Emo\u00e7\u00e3o, Execu\u00e7\u00e3o.  </p> <ul> <li>Situa\u00e7\u00e3o: Quando a problem\u00e1tica \u00e9 apresentado a IA;</li> <li>Pensamento: Quando a situa\u00e7\u00e3o \u00e9 interpretada;</li> <li>Emo\u00e7\u00e3o: Quando uma interpreta\u00e7\u00e3o mais aprofundada resultada de um pensamento, como uma emo\u00e7\u00e3o;</li> <li>Execu\u00e7\u00e3o: Uma a\u00e7\u00e3o em resposta a emo\u00e7\u00e3o;</li> </ul>"},{"location":"portifolios/portifolio1/#pensando-racionalmente-leis-do-pensamento","title":"Pensando Racionalmente (\"Leis do Pensamento\")","text":"<p>O pensamento racional tem um aspecto diferente do pensamento de forma humana que se focava na emo\u00e7\u00e3o para executar algo, o pensamento racional se foca na l\u00f3gica, no silogismo, e na probabilidade de resultados. Este tipo de pensamento gera um modelo mais racional para uma IA, trazendo um aspecto de conseguir raciocinar e prever baseado nos dados, mas em contra partida, ela n\u00e3o gera em si um comportamento inteligente, pois n\u00e3o leva em considera\u00e7\u00e3o aspectos fora dos dados como a pr\u00f3pria \"emo\u00e7\u00e3o\".</p>"},{"location":"portifolios/portifolio1/#agente-racional","title":"Agente Racional","text":"<p>Um agente \u00e9 algo que age sobre um ambiente, com isso para um agente ser inteligente \u00e9 esperado que ele cumpra alguns crit\u00e9rios, onde tais crit\u00e9rios s\u00e3o:</p> <ul> <li>opere de forma aut\u00f4noma,</li> <li>perceba seu ambiente, </li> <li>persista por um per\u00edodo de tempo prolongado, </li> <li>adapte-se a mudan\u00e7as </li> <li>crie e busque objetivos</li> </ul> <p>Quando um agente cumpre esses requisitos ele \u00e9 considerado um agente inteligente, para deixar mais claro essa ideia podemos pegar dois exemplos, o primeiro de um ser humano agindo em um ambiente, e o segundo o exemplo de uma IA agindo sobre um ambiente:</p> <ul> <li> <p>Exemplo: </p> <p>Um homem chega a uma cafeteria com o objetivo de comprar um copo de caf\u00e9, ao chegar no local ele olha ao redor e encontra a fila do balc\u00e3o, ele se desloca a ela e entra ao final da fila, ele come\u00e7a a perceber que a fila n\u00e3o est\u00e1 diminuindo de maneira fl\u00faida e que est\u00e1 muito grande para esperar, ao olhar ao seu redor novamente e v\u00ea que no outro lado da rua existe uma caferetira que parece estar menos cheia e com uma fila menor, com isso ele se desloca para a outra cafeteria para ser atendido com mais agilidade fazendo com que ele alcance o seu objetivo de forma mais r\u00e1pida.</p> </li> <li> <p>Exemplo:</p> <p>Um carro aut\u00f4nomo tem o objetivo de se deslocar de um ponto A a um ponto B, ele possui 3 rotas que pode utilizar, e foi programado para seguir a rota mais r\u00e1pida pois seus passageiros costumam ter pressa para se deslocar, ao analisar as rotas poss\u00edveis ele identifica que a rota mais r\u00e1pida \u00e9 a n\u00famero 2, a partir disso ele come\u00e7a a viagem, no meio do caminho ele recebe um sinal em seu GPS que houve um acidente e que a rota n\u00famero 2 est\u00e1 interditada acrescentando um longo tempo de espera aos carros que queiram utiliz\u00e1-la, com isso o carro executa uma nova verifica\u00e7\u00e3o para identificar o novo caminho a ser percorrido, em sua verifica\u00e7\u00e3o ele identifica que a rota 3 parece uma boa op\u00e7\u00e3o mesmo sendo a mais longa dentre \u00e0s 3 rotas, ele se desloca para a via da rota 3 e continua seguindo o seu caminho, ap\u00f3s alguns quil\u00f4metros, ele chega a seu destino no ponto B. Mesmo n\u00e3o que ele n\u00e3o tenha conseguido percorrer o caminho da rota 2 que possu\u00eda o menor tempo, ele conseguiu se adaptar a mudan\u00e7a repentina e conseguiu chegar ao objetivo no menor tempo calculado, mesmo que isso tenha feito ele rodar mais quil\u00f4metros.</p> </li> </ul>"},{"location":"portifolios/portifolio1/#modelo-padrao","title":"Modelo Padr\u00e3o","text":"<p>Existe uma abordagem para as IA's que prevalece na maior parte da hist\u00f3ria nesse campo de conhecimento, que \u00e9 a abordagem racional, com isso as IA's se concentravam no estudo e contru\u00e7\u00e3o de agentes que fazer a \"coisa certa\", sendo que a \"coisa certa\" \u00e9 a que definimos para ela como objetivo, como no exemplo anterior que o carro aut\u00f4nomo tinha o objetivo de chegar ao ponto B no menor tempo poss\u00edvel. Por ser t\u00e3o difundido e ter prevalecido como padr\u00e3o pela maior parte do tempo na hist\u00f3ria, ele foi considerado o modelo padr\u00e3o.</p> <p>Este modelo padr\u00e3o tem problemas relacionados a sua utiliza\u00e7\u00e3o a longo prazo, a priori temos que o modelo esse segue somente o padr\u00e3o que especificamos para ele, e no mundo real, o objetivo nem sempre consegue ser especificado da melhor forma, com isso introduzindo falhas no modelo. Esse problema que engloba as quest\u00f5es dos objetivos programados com o alinhamento dos objetivos reais \u00e9 conhecido como \"Problema de Alinhamento de Valor\". </p> <p>Se pegarmos o exemplo 2 e pensarmos no objetivo do carro que era chegar ao ponto B pela rota com o menor tempo para satisfazer o desejo do usu\u00e1rio que era o deslocamento r\u00e1pido, mas o usu\u00e1rio tamb\u00e9m deseja que o caminho para o ponto B seja uma rota mais segura, a IA pode n\u00e3o validar esse desejo pois sua programa\u00e7\u00e3o segue o objetivo da rota mais r\u00e1pida e por consequ\u00eancia, a rota mais r\u00e1pida \u00e9 a menos segura. </p>"},{"location":"portifolios/portifolio1/#aplicacoes-atuais-de-ia","title":"Aplica\u00e7\u00f5es Atuais de IA","text":"<p>Antes de vermos onde nos dias atuais existem as aplica\u00e7\u00f5es de IA, devemos entender primeiramente o que s\u00e3o sistemas especialistas e sua import\u00e2ncia.  </p> <p>Sistemas especialistas s\u00e3o modelos de IA especializado em tarefas e dom\u00ednios espec\u00edficos, ou seja, ele \u00e9 treinado para resolver problemas espec\u00edficos. Grandes empresas se utilizam de sistemas deste modelo para otimizar processos ou personalizar suas ferramentas. A seguir vamos ver alguns exemplos de forma detalhada:</p> <ul> <li> <p>Exemplo:</p> <p>Um modelo que analisa os dados de clientes da empresa e verifica as tend\u00eancias de vendas baseado em per\u00edodos espec\u00edficos do ano. Este modelo costuma ser muito utilizado em empresas que mudam seus produtos de acordo com os meses do ano ou novas tend\u00eancias que surgem. Um modelo de IA para auxiliar analistas de dados \u00e9 muito importante, principalmente quando a base de dados \u00e9 extremamente extensa.</p> </li> <li> <p>Exemplo:</p> <p>Um modelo que atua em tempo real no mercado de a\u00e7\u00f5es, analisando as altas e baixas do mercado e fazendo transa\u00e7\u00f5es de forma autom\u00e1tica para eliminar a necessidade de um analista verificando dados o tempo todo. Esse tipo de automa\u00e7\u00e3o se tornou bastante popular nos \u00faltimos anos, especialistas em a\u00e7\u00f5es confiaram seus investimentos nas IA's, e em muitos casos eles conseguiram dobrar suas a\u00e7\u00f5es.</p> </li> <li> <p>Exemplo:</p> <p>Um modelo que analisa imagens de tomografias e identificam anomalias para descobrir ou prever tumores cerebrais. N\u00e3o \u00e9 algo muito popularizado ainda aqui no Brasil, mas sua utiliza\u00e7\u00e3o pode dar um feedback a mais ao especialista que est\u00e1 analisando os pacientes.</p> </li> <li> <p>Exemplo:</p> <p>Um modelo que analisa imagens de folhas de plantas e identifica a doen\u00e7a que est\u00e1 presente na imagem, ou um drone acoplado com uma c\u00e2mera que identifica focos de pragas dentro de planta\u00e7\u00f5es em tempo real. Esses tipos de modelos ainda n\u00e3o s\u00e3o muito populares dentro do agroneg\u00f3cio pelo custo de sua implanta\u00e7\u00e3o, mas grandes plantadores j\u00e1 utilizam essas ferramentas para melhorar o cuidado com suas planta\u00e7\u00f5es.</p> </li> <li> <p>Exemplo:</p> <p>Modelos que ajudam sistemas de e-commerce a fornecerem produtos de acordo com o interesse dos usu\u00e1rios, e baseados em seus dados de visitas e pesquisas em outros sites. Esses modelos s\u00e3o amplamentes usados nos dias atuais, dentre algumas empresas que se utilizam desses modelos temos a Amazon, Mercado Livre, Walmart, e v\u00e1rias outras grandes marcas.</p> </li> </ul>"},{"location":"portifolios/portifolio1/#riscos-e-beneficios-da-ia","title":"Riscos e Benef\u00edcios da IA","text":"<p>Ap\u00f3s entender o que s\u00e3o IA's e algumas de suas aplica\u00e7\u00f5es presentes no nosso cotidiano, devemos come\u00e7ar a pensar sobre quais seus riscos e benef\u00edcios para a humanidade. At\u00e9 o momento vimos que a utiliza\u00e7\u00e3o de IA's pode ajudar diversos setores, mas a observa\u00e7\u00e3o dos seus riscos para a humanidade \u00e9 um fator crucial para entender completamente a capacidade que IA's possuem.</p> <p>Vimos anteriormente nos exemplos do t\u00f3pico passado que a IA pode ser utilizada na identifica\u00e7\u00e3o de doen\u00e7as no setor m\u00e9dico, pode ajudar os agricultores no cultivo de suas planta\u00e7\u00f5es, tamb\u00e9m serve an\u00e1lise de dados em larga escala de grandes empresas.</p> <p>Dentro desses exemplos podemos citar os seus riscos tamb\u00e9m, no caso do setor m\u00e9dico, temos a falsa identifica\u00e7\u00e3o de problemas ou falta desta identifica\u00e7\u00e3o, os dois sendo riscos perigosos para essa \u00e1rea, no caso do sistema de aux\u00edlio para os agricultores temos o risco da falsa identifica\u00e7\u00e3o de doen\u00e7as ou a identifica\u00e7\u00e3o errada, que pode induzir o agricultor a fornecer um tratamento errado para a planta\u00e7\u00e3o, afetando o plantio, agora indo para o caso das an\u00e1lises de grandes dados em empresas, e um mal tratamento dos dados pela IA pode afetar todo o planejamento da empresa causando uma problem\u00e1tica nas vendas e na produ\u00e7\u00e3o de produtos.</p> <p>Riscos e benef\u00edcios n\u00e3o faltam quando se trata do uso de IA's, mas muitas de suas utiliza\u00e7\u00f5es devem ser moderadas pelo pr\u00f3prio usu\u00e1rio para evitar gerarem problem\u00e1ticas no mundo real. </p> <p>Trazendo essa vis\u00e3o do uso em mundo real, algumas IA's podem ser criadas especificamente para prejudicar a humanidade, desde seu uso em guerras, at\u00e9 a cria\u00e7\u00e3o de armas biol\u00f3gicas, por isso, alguns limites devem ser impostos desde a cria\u00e7\u00e3o das IA's para que elas n\u00e3o possam prejudicar a humanidade de alguma forma. No Brasil temos a lei 759/23 que regulamenta o uso da IA.</p>"},{"location":"portifolios/portifolio1/#ambientes","title":"Ambientes","text":"<p>Como j\u00e1 foi conversado anteriormente agentes s\u00e3o algo que agem sobre o ambiente, um agente para ser inteligente ele deve cumprir alguns requisitos, tais requisitos j\u00e1 foram expostos anteriormente, mas de maneira simples, para ser inteligente ele deve \"pensar e raciocinar\". At\u00e9 o momento j\u00e1 entendemos o que s\u00e3o agentes inteligentes e que para ser agente ele deve agir, agora veremos onde ele deve agir, qual o seu ambiente.</p> <p>Antes de come\u00e7armos a explorar o ambiente devemos conhecer o que \u00e9 a a\u00e7\u00e3o de um agente, a fun\u00e7\u00e3o agente e o programa agente que s\u00e3o termos essenciais para a compreens\u00e3o total. </p> <p>A a\u00e7\u00e3o de um agente depende do seu objetivo, ou seja para o que ele foi progamado, e de toda a sua percep\u00e7\u00e3o do ambiente, e n\u00e3o pode ser afetado por algo que n\u00e3o foi percebido. A fun\u00e7\u00e3o agente \u00e9 aquela que mapeia as sequ\u00eancias de percep\u00e7\u00e3o em uma a\u00e7\u00e3o. E por \u00faltimo, o programa agente \u00e9 a implementa\u00e7\u00e3o da fun\u00e7\u00e3o agente em um sistema. Com essas informa\u00e7\u00f5es, conseguimos prosseguir com nosso assunto sobre os ambientes de agentes.</p> <p>Um ambiente de um agente \u00e9 o local onde o agente atua, esse ambiente varia de acordo com o agente, por exemplo, um carro aut\u00f4nomo atua nas ruas de uma cidade, ent\u00e3o o ambiente do carro ser\u00e1 as ruas, pensando no sistema de drones para identifica\u00e7\u00e3o de doen\u00e7as nas planta\u00e7\u00f5es, o ambiente do drone seria as planta\u00e7\u00f5es.</p> <p>Sempre antes de desenvolver um agente, devemos especificar o seu ambiente de atua\u00e7\u00e3o, e para auxiliar na especifica\u00e7\u00e3o desse ambiente, podemos usar a \"Descri\u00e7\u00e3o PEAS(Performance, Enviroment, Actuators, Sensors)\", que \u00e9 um framework de perguntas para nos ajudar a detalhar o ambiente, os detalhes da \"Descri\u00e7\u00e3o PEAS\" \u00e9:</p> <ul> <li>P: Qual \u00e9 a medida de performance desejada?</li> <li>E: Como \u00e9 o ambiente de tarefa?</li> <li>A: Quais s\u00e3o os atuadores dispon\u00edveis para desempenhar a\u00e7\u00f5es?</li> <li>S: Quais s\u00e3o os sensores dispon\u00edveis para explorar o ambiente?</li> </ul> <p>Ao discorrer sobre a \"Descri\u00e7\u00e3o PEAS\", vemos mais dois termos importantes para serem analisados em rela\u00e7\u00e3o a agentes, atuadores e sensores. Os atuadores s\u00e3o as ferramentas dispon\u00edveis para o agente agir sobre o ambiente, e os sensores s\u00e3o os dispositivos integrados ao agente que ele utiliza para observar o ambiente em que atua.</p> <p>Para um melhor detalhamento da utiliza\u00e7\u00e3o da \"Descri\u00e7\u00e3o PEAS\", podemos dar um exemplo simples de um agente e seu ambiente:</p> <ul> <li>Exemplo:</li> </ul> Agente Performance Enviroment Actuators Sensors IA para diagn\u00f3stico de tumor Identificar tumor, prever futuros tumores Hospitais, Cl\u00ednicas M\u00e9dicas Monitor para amostra de resultados C\u00e2mera para an\u00e1lise das imagens"},{"location":"portifolios/portifolio1/#propriedades-do-ambiente","title":"Propriedades do Ambiente","text":"<p>Assim como os agentes, o ambiente tamb\u00e9m possui propriedades para sua defini\u00e7\u00e3o, e essas propriedades s\u00e3o importantes para o entendimento de como o agente ir\u00e1 atuar, a seguir, temos as propriedades que o ambiente pode possuir:</p> <ul> <li>Totalmente observ\u00e1vel vs. Parcialmente observ\u00e1vel vs. N\u00e3o observ\u00e1vel;</li> <li>Agente \u00fanico vs. Multiagente;</li> <li>Determin\u00edstico vs. N\u00e3o determin\u00edstico;</li> <li>Epis\u00f3dico vs. Sequencial;</li> <li>Est\u00e1tico vs. Din\u00e2mico;</li> <li>Discreto vs. Cont\u00ednuo;</li> <li>Conhecido vs. Desconhecido</li> </ul>"},{"location":"portifolios/portifolio1/#totalmente-observavel-vs-parcialmente-observavel-vs-nao-observavel","title":"Totalmente observ\u00e1vel vs. Parcialmente observ\u00e1vel vs. N\u00e3o observ\u00e1vel","text":"<p>O ambiente ele \u00e9 totalmente observ\u00e1vel quando o agente consegue enxergar todo o ambiente em que ele atua, recebendo todas as informa\u00e7\u00f5es poss\u00edveis e relevantes para suas escolhas, um exemplo bastante utilizado para essa propriedade \u00e9 o tabuleiro de xadrez, onde o agente consegue ver e analisar todo o ambiente.</p> <p>O ambiente parcialmente observ\u00e1vel, acontece quando o agente s\u00f3 tem acesso a informa\u00e7\u00f5es necess\u00e1rias para sua tomada de decis\u00e3o, um exemplo claro s\u00e3o jogos de carta como Uno, onde o agente que seria um jogador, n\u00e3o tem acesso \u00e0s cartas de outro jogador.</p> <p>Por \u00faltimo, quando o ambiente n\u00e3o \u00e9 observ\u00e1vel, que se d\u00e1 pelo agente n\u00e3o conseguir ter acesso aos dados do ambiente, e se baseia somente em informa\u00e7\u00f5es internas.</p> <p>Um fator interessante que deve ser levado em considera\u00e7\u00e3o durante a an\u00e1lise do ambiente no quesito de observa\u00e7\u00e3o, \u00e9 que a quantidade de sensores que o agente pode ter, afeta a propriedade do ambiente.</p>"},{"location":"portifolios/portifolio1/#agente-unico-vs-multiagente","title":"Agente \u00danico vs. Multiagente","text":"<p>De forma clara e direta, a defini\u00e7\u00e3o de agente \u00fanico e multiagente se d\u00e1 pela quantidade de agentes atuando sobre o mesmo ambiente, por exemplo, temos o carro aut\u00f4nomo, que se pensarmos somente no carro, ele se torna um agente \u00fanico, mas se pensarmos nele atuando em seu ambiente, e contando que ele trafega em ruas onde outros carros tamb\u00e9m trafegam, o ambiente se torna multiagentes, pois os outros carros tamb\u00e9m s\u00e3o considerados agentes no ambiente, pois decis\u00f5es deles podem afetar decis\u00f5es do nosso agente.</p>"},{"location":"portifolios/portifolio1/#deterministico-vs-nao-deterministico","title":"Determin\u00edstico vs. N\u00e3o Determin\u00edstico","text":"<p>O ambiente \u00e9 considerado determin\u00edsticos quando as a\u00e7\u00f5es de um agente determinam o seu pr\u00f3ximo estado, como por exemplo, um jogo de xadrez onde a jogada do agente determina as poss\u00edveis pr\u00f3ximas a\u00e7\u00f5es. Em contra partida temos o ambiente n\u00e3o determin\u00edstico(Estoc\u00e1stico) que se d\u00e1 quando as a\u00e7\u00f5es do agente n\u00e3o determinam exatamente qual ser\u00e1 seu pr\u00f3ximo estado, por exemplo em um carro aut\u00f4nomo, onde diversos fatores podem mudar seu estado, como uma via interditada, um sem\u00e1foro e etc.</p>"},{"location":"portifolios/portifolio1/#episodico-vs-sequencial","title":"Epis\u00f3dico vs. Sequencial","text":"<p>Em um ambiente epis\u00f3dico, o agente somente atua no ambiente quando realmente \u00e9 necess\u00e1rio, necessitando que algo o ative para que ele possa agir. Ao contr\u00e1rio do ambiente epis\u00f3dico temos o sequencial, onde o agente executa constantemente a\u00e7\u00f5es e que influenciam suas pr\u00f3ximas a\u00e7\u00f5es.</p>"},{"location":"portifolios/portifolio1/#estatico-vs-dinamico","title":"Est\u00e1tico vs. Din\u00e2mico","text":"<p>O ambiente \u00e9 considerado est\u00e1tico quando ele n\u00e3o muda durante a execu\u00e7\u00e3o de um agente, como por exemplo modelos que analisam imagens de tomografia, a imagem n\u00e3o muda durante a atua\u00e7\u00e3o do modelo. J\u00e1 no ambiente din\u00e2mico, temos um ambiente que pode ou n\u00e3o mudar a todo momento, como por exemplo o ambiente do carro aut\u00f4nomo, que pode ter altera\u00e7\u00f5es realizadas por outro agente, enquanto o agente principal que \u00e9 o carro se desloca de um ponto a outro.</p>"},{"location":"portifolios/portifolio1/#discreto-vs-continuo","title":"Discreto vs. Cont\u00ednuo","text":"<p>Um ambiente \u00e9 discreto quando ele possui um n\u00famero finito de a\u00e7\u00f5es para serem executadas pelo agente, como por exemplo o modelo de identifica\u00e7\u00e3o de tumores, onde suas a\u00e7\u00f5es s\u00e3o somente analisar e mostrar os resultados ao usu\u00e1rio, ao contr\u00e1rio do ambiente cont\u00ednuo, onde o n\u00famero de a\u00e7\u00f5es n\u00e3o pode ser contabilizado, neste caso temos o exemplo do carro aut\u00f4nomo que executa diversas a\u00e7\u00f5es, e que pode surgir a necessidade de novas a\u00e7\u00f5es de forma indeterminada.</p>"},{"location":"portifolios/portifolio1/#conhecido-vs-desconhecido","title":"Conhecido vs. Desconhecido","text":"<p>O ambiente \u00e9 conhecido quando o agente possui conhecimento pr\u00e9vio sobre o ambiente em que vai executar. J\u00e1 para o desconhecido, o agente n\u00e3o possui conhecimento pr\u00e9vio sobre o ambiente e se adapta de acordo com seu treinamento seguindo seu objetivo.</p>"},{"location":"portifolios/portifolio1/#arquitetura-do-agente","title":"Arquitetura do Agente","text":"<p>Neste t\u00f3pico abordaremos a fundo como funciona a arquitetura de um agente inteligente detalhando um pouco mais o que \u00e9 Programa Agente, e Fun\u00e7\u00e3o Agente e o que gera um agente.</p> <p>Como j\u00e1 foi abordado, vimos que uma fun\u00e7\u00e3o agente \u00e9 uma forma abstrata que mapeia as sequ\u00eancias de percep\u00e7\u00f5es de um agente para as a\u00e7\u00f5es correspondentes, ou seja, define as regras de a\u00e7\u00e3o do agente dentro de um ambiente, e o programa agente \u00e9 sua aplica\u00e7\u00e3o concreta da fun\u00e7\u00e3o agente, isso sendo em algoritmos, ou c\u00f3digo, ou qualquer tipo de implementa\u00e7\u00e3o da fun\u00e7\u00e3o.</p> <p>Outro termo importante para este t\u00f3pico \u00e9 a Arquitetura do Agente, esta arquitetura \u00e9 definida como o dispositivo que possui sensores e atuadores f\u00edsicos, onde o agente ir\u00e1 controlar, com isso, temos a descri\u00e7\u00e3o completa da l\u00f3gica que forma um agente:</p> <p>Agente = Programa Agente + Arquitetura do Agente</p> <p>A seguir abordaremos um pouco mais a fundo algumas caracter\u00edsticas e exemplos de programa agente para fixarmos o que j\u00e1 foi abordado sobre o assunto.</p>"},{"location":"portifolios/portifolio1/#programa-agente","title":"Programa Agente","text":"<p>Como visto no anteriormente, o programa agente \u00e9 a implementa\u00e7\u00e3o concreta de uma fun\u00e7\u00e3o agente, ou seja, ela pode ser a implementa\u00e7\u00e3o da abstra\u00e7\u00e3o em um c\u00f3digo, ou algoritmo que ser\u00e1 implementado em uma arquitetura agente que seria a parte f\u00edsica do agente. </p> <p>Se utilizarmos o exemplo anterior de um agente que realiza a an\u00e1lise de imagens de tomografias para identificar e ou prever tumores, teremos um algoritmo da seguinte forma sequencial:</p> <ul> <li>Ativa o modelo de agente j\u00e1 treinado </li> <li>Envia a imagem para o agente </li> <li>O agente normaliza e faz o pr\u00e9-processamento da imagem antes da an\u00e1lise </li> <li>O agente analisa a imagem passando elas por suas camadas de processamento </li> <li>Ele classifica a imagem como: tumor presente ou sem tumor </li> <li>Ele retorna para o usu\u00e1rio o resultado da sua an\u00e1lise junto com a probabilidade da certeza do diagn\u00f3stico que est\u00e1 em porcentagem de precis\u00e3o.</li> </ul> <p>Baseado nesse algoritmo, se tentarmos implementar isto em um c\u00f3digo em python por exemplo, teremos um resultado parecido com o da Imagem 1:</p> Imagem 1: C\u00f3digo do algoritmo de agente de indentifica\u00e7\u00e3o de tumor <p></p> Fonte: ChatGPT <p>Existe tamb\u00e9m uma abordagem orientada por tabela, que mapeia todas as poss\u00edveis a\u00e7\u00f5es e sequ\u00eancias de um agente em uma tabela, ent\u00e3o o agente s\u00f3 precisa consultar a tabela para realizar sua proxima\u00e7\u00e3o a\u00e7\u00e3o e mudar o seu estado. Essa abordagem possui uma grande problem\u00e1tica, alguns agentes necessitam de milhares de informa\u00e7\u00e3o para poder agir, e fazer o mapeamento dessas a\u00e7\u00f5es em uma tabela seria quase imposs\u00edvel, temos o exemplo do jogo de xadrez, onde se fossemos mapear suas a\u00e7\u00f5es e sequ\u00eancias, ter\u00edamos uma problem\u00e1tica muito grande, pois o jogo de xadrez possui um mais ou menos 10^150 entradas, portanto, fazer esse mapeamento levaria anos.</p> <p>Vendo essa problem\u00e1tica, a melhor solu\u00e7\u00e3o seria usar estrat\u00e9gias algoritmicas para que o agente possa decidir suas a\u00e7\u00f5es, deixando suas representa\u00e7\u00f5es mais compactas e eficientes para serem depois transformadas em c\u00f3digo.</p>"},{"location":"portifolios/portifolio1/#tipos-de-agentes","title":"Tipos de Agentes","text":"<p>Quando falamos de agentes entendemos que s\u00e3o algo que agem, mas tamb\u00e9m devemos entender que cada agente tem suas caracter\u00edsticas e seu tipo. Neste t\u00f3pico iremos analisar alguns tipos de agentes para entender suas diferen\u00e7as e como atuam. A seguite alguns dos principais modelos de agentes:</p> <ul> <li>Agentes de Reflexo Simples;</li> <li>Agentes de Reflexo Baseado em Modelo;</li> <li>Agentes Baseados em Objetivos;</li> <li>Agentes Utilit\u00e1rios;</li> <li>Agentes Baseados em Servi\u00e7os P\u00fablicos;</li> <li>Agentes de Aprendizagem;</li> </ul> <p>Nos t\u00f3picos a seguir, iremos de discutir um pouco mais sobre cada um desses modelos de agentes trazendo exemplos para que o entendimento seja mais profundo sobre cada um.</p>"},{"location":"portifolios/portifolio1/#agentes-de-reflexo-simples","title":"Agentes de Reflexo Simples","text":"<p>Um agente de reflexo simples atua dentro de um ambiente totalmente observ\u00e1vel, sendo que suas a\u00e7\u00f5es s\u00e3o baseadas na sua percep\u00e7\u00e3o atual e em regras predefinidas, ou seja, \u00e9 um agente simples que possui limita\u00e7\u00f5es em suas a\u00e7\u00f5es. </p> <p>Exemplo:</p> <p>Um agente que identifica se uma embalagem est\u00e1 estragada ou n\u00e3o em uma esteira de produ\u00e7\u00e3o, onde sua a\u00e7\u00e3o retirar o produto da esteira</p>"},{"location":"portifolios/portifolio1/#agentes-de-reflexo-baseado-em-modelo","title":"Agentes de Reflexo Baseado em Modelo","text":"<p>Este agente atua em um ambiente parcialmente observ\u00e1vel, este modelo \u00e9 um pouco diferente do anterior quando se trata de suas decis\u00f5es, como o agente n\u00e3o tem conhecimento total do ambiente em que est\u00e1 atuando, e com isso n\u00e3o possui todos os dados, ele cont\u00e9m um hist\u00f3rico de percep\u00e7\u00f5es anteriores que o ajuda a tomar decis\u00f5es futuras junto com os dados atuais, esse conjunto de dados \u00e9 chamado de estado interno. Este tipo de agente possui dois modelos, um transit\u00f3rio que descreve como o ambiente muda com a a\u00e7\u00e3o do agente, e um modelo sensorial que descreve o funcionamento e limita\u00e7\u00f5es dos sensores.</p> <p>Exemplo:</p> <p>Como exemplo podemos pensar em um agente de GPS que verificar diversos tipos de eventos como sem\u00e1foros, acidentes, rodovias fechadas, e atualiza as rotas que devem ser percorridas.</p>"},{"location":"portifolios/portifolio1/#agentes-baseados-em-objetivos","title":"Agentes Baseados em Objetivos","text":"<p>O agente baseado em objetivos atua em ambiente parcialmente observ\u00e1veis, onde ele atua com um conjunto mais complexo de decis\u00f5es, pois ele precisa realizar um objetivo espec\u00edfico. Este agente realiza um planejamento antes de come\u00e7ar a realizar o seu objetivo, ele analisa diversos fatores que interferem em sua execu\u00e7\u00e3o e analisa sequ\u00eancias de etapas para encontrar o melhor caminho para completar o seu objetivo.</p> <p>Exemplo</p> <p>Como exemplo deste agente, podemos imaginar um agente de entrega dentro de um escrit\u00f3rio, esse agente \u00e9 respons\u00e1vel por entregar diversos materiais pelo escrit\u00f3rios do pr\u00e9dio, ele deve sempre planejar sua rota e analisar poss\u00edveis problemas no caminho. Supondo que ele tenha que entregar em dois andares diferentes, e ele tem que fazer os percursos no menor tempo poss\u00edvel, ele tra\u00e7a sua rota e come\u00e7a a execut\u00e1-la, no caminho ele identifica que n\u00e3o ser\u00e1 poss\u00edvel percorrer a rota tra\u00e7ada pq est\u00e1 havendo a limpeza de um dos corredores, ele deve se adaptar a essa mudan\u00e7a e analisar a nova rota poss\u00edvel que seja feita no menor tempo.</p>"},{"location":"portifolios/portifolio1/#agentes-utilitarios","title":"Agentes Utilit\u00e1rios","text":"<p>Este tipo de agente \u00e9 usado para proporcionar o m\u00e1ximo de utilidade e maximizar a satisfa\u00e7\u00e3o geral definida em seu modelo. Ele se utiliza de algoritmos para analisar diversos resultados e prioriza o que trar\u00e1 a maior satisfa\u00e7\u00e3o do usu\u00e1rio. </p> <p>Exemplo:</p> <p>Agente que atuam no oferecimento de conte\u00fado personalizado, podemos citar streamers de v\u00eddeo como youtube, que analisa seus dados para oferecer o conte\u00fado que o usu\u00e1rio tem maior probabilidade de assistir.</p> <p>Um fato importante sobre esse agente, \u00e9 que nem sempre o que ele trar\u00e1 como resultado, seja o melhor de fato.</p>"},{"location":"portifolios/portifolio1/#agentes-baseados-em-servicos-publicos","title":"Agentes Baseados em Servi\u00e7os P\u00fablicos","text":"<p>O agente nesse modelo tem o foco de maximizar o m\u00e1ximo que puderem os desejos do usu\u00e1rios. Eles usam algoritmos complexos para analisar todas os poss\u00edveis cen\u00e1rios e resultados, e escolhem aquele em que mais ir\u00e1 beneficiar o usu\u00e1rio.</p> <p>Exemplo:</p> <p>Um agente que analisa diversos sites em busca do valor do mesmo produto, e que trazem como resultado o local com o menor pre\u00e7o de compra.</p>"},{"location":"portifolios/portifolio1/#agentes-de-aprendizagem","title":"Agentes de Aprendizagem","text":"<p>Agentes de aprendizagem s\u00e3o modelos altamente avan\u00e7ados que baseiam suas a\u00e7\u00f5es em aprendizado cont\u00ednuo baseado em dados passados e feedback, ou seja, quanto mais ele age, mais ele aprender, mais ele refina suas a\u00e7\u00f5es e planeja novas sequ\u00eancias.</p> <p>Exemplo:</p> <p>Um agente que atua na bolsa de valores \u00e9 um bom exemplo que agente de aprendizado, pois ele tem uma base de conhecimento pr\u00e9via, mas com o tempo, enquanto ele age dentro da bolsa vendendo e comprando a\u00e7\u00f5es, ele recebe diferentes feedbacks sobre as transa\u00e7\u00f5es e analisa as tend\u00eancias da bolsa.</p>"},{"location":"portifolios/portifolio1/#representacao-de-estados","title":"Representa\u00e7\u00e3o de Estados","text":"<p>Quando tratamos do assunto de agentes, \u00e9 muito importante entendermos os estados em que os agentes se encontram e como s\u00e3o representados para compreender como os agentes ir\u00e3o agir no ambiente em que atuam. Quando falamos de estados podemos definir 3 representa\u00e7\u00f5es para esses estados, a at\u00f4mica, a fatorial e a estruturada. A seguir vamos entender mais a fundo o que cada representa\u00e7\u00e3o significa e onde \u00e9 aplicada.</p>"},{"location":"portifolios/portifolio1/#representacao-atomica","title":"Representa\u00e7\u00e3o At\u00f4mica","text":"<p>A representa\u00e7\u00e3o at\u00f4mica \u00e9 definida quando o estado \u00e9 uma unidade \u00fanica e indivis\u00edvel. Um exemplo para essa representa\u00e7\u00e3o seria um controle de sem\u00e1foro respons\u00e1vel pelo tr\u00e1fego de uma via, onde o estado do sem\u00e1foro seria a cor que ele estaria no momento. O agente nesse exemplo, agiria somente baseado nas regras predefinidas em sua implementa\u00e7\u00e3o, e n\u00e3o seria afetado por outras vari\u00e1veis como a quantidade de carros na via, ou o hor\u00e1rio do dia.</p>"},{"location":"portifolios/portifolio1/#representacao-fatorial","title":"Representa\u00e7\u00e3o Fatorial","text":"<p>Esta representa\u00e7\u00e3o se d\u00e1 quando o estado do agente \u00e9 representado por mais de uma vari\u00e1vel. Para exemplificar este caso, podemos pensar no jogo de Uno citado em exemplos anteriores, um agente teria que analisar diversos fatores que acontecem no jogo, como por exemplo, a quantidade de cartas que cada jogador possui, a quantidade de cartas que ainda existe no baralho, as cartas coringas que ainda existem no jogo, e assim por diante.</p>"},{"location":"portifolios/portifolio1/#representacao-estruturada","title":"Representa\u00e7\u00e3o Estruturada","text":"<p>A representa\u00e7\u00e3o estruturada \u00e9 definida como a mais complexa entre as 3 representa\u00e7\u00f5es, pois os estados neste caso s\u00e3o representados por uma \"teia\" de conex\u00f5es que interligam diversos objetos e entidades para a an\u00e1lise, diferente do modelo anterior que se utilizava de vari\u00e1veis independentes, este modelo se importa com vari\u00e1veis externas e suas rela\u00e7\u00f5es. Para este modelo de representa\u00e7\u00e3o, podemos citar o carro aut\u00f4nomo, que age baseado em diversos fatores e entidades, como por exemplo, ele analisa as rotas do GPS, os obst\u00e1culos que ele deve desviar, problemas que podem surgir, e etc.</p>"},{"location":"portifolios/portifolio1/#conclusao","title":"Conclus\u00e3o","text":"<p>Baseado em tudo que vimos at\u00e9 o presente momento, obtivemos uma vis\u00e3o abstrata e detalhada sobre o que \u00e9 Intelig\u00eancia Artifical, modelos e conceitos do que gera a defini\u00e7\u00e3o final de um agente inteligente e como foi gerado o modelo padr\u00e3o de IA, tamb\u00e9m analisamos riscos, benef\u00edcios e implementa\u00e7\u00f5es da IA no mundo atual, entendendo seus pr\u00f3s e contras em cada exemplo formando opini\u00f5es sobre seus usos. Ap\u00f3s entender os conceitos mais b\u00e1sicos sobre IA, nos aprofundamos no assunto de agentes, onde conseguimos ter uma vis\u00e3o ampliada do que s\u00e3o agentes, suas caracter\u00edsticas e propriedades, o ambiente em que atuam e as propriedades de um ambiente que influenciam o comportamento e a modelagem de um agente, fazendo com que entedessemos sobre a arquitetura do agente, vimos um pouco dos tipos de agentes existentes com suas caracter\u00edsticas e aplica\u00e7\u00f5es, fazendo com que pudessemos compreender como tarefas simples e complexas s\u00e3o realizadas por agentes, e por fim entendemos os estados de um agente.</p> <p>Ap\u00f3s toda esse estudo e an\u00e1lise realizada neste artigo, podemos concluir que IA's s\u00e3o entidades complexas que possuem muitos vi\u00e9s em suas defini\u00e7\u00f5es e conceitos, algumas formas abstratas de IA podem ser utilizadas para resolver grandes e ou extensos problemas do mundo atual, entender seus riscos e benef\u00edcios em exemplos de aplica\u00e7\u00f5es nos trouxe certezas e d\u00favidas sobre sua utiliza\u00e7\u00e3o do dia a dia, onde essas d\u00favidas devem ser exploradas e analisadas para uma melhor compreenss\u00e3o sobre os assuntos. Entender sobre agentes e seus ambientes nos fez perceber que, gerar um agente inteligente n\u00e3o \u00e9 algo simples, e que deve ser feito uma an\u00e1lise detalhada do ambiente em que ele agir\u00e1.</p>"},{"location":"portifolios/portifolio1/#referencias","title":"Refer\u00eancias","text":"<ul> <li> <p>RUSSELL, Stuart; NORVIG, Peter. Intelig\u00eancia Artificial: Uma Abordagem Moderna \u2013 3\u00aa edi\u00e7\u00e3o. </p> </li> <li> <p>INTELIG\u00caNCIA. Wikipedia. Dispon\u00edvel em: https://pt.wikipedia.org/wiki/Intelig%C3%AAncia#cite_note-etimo-intelecto-3. Acesso em: 16/11/2024.</p> </li> <li> <p>IBM. O que \u00e9 Intelig\u00eancia Artificial? Dispon\u00edvel em: https://www.ibm.com/br-pt/topics/artificial-intelligence. Acesso em: 16/11/2024.</p> </li> <li> <p>MICROSOFT AZURE. O que \u00e9 Intelig\u00eancia Artificial? Dispon\u00edvel em: https://azure.microsoft.com/pt-pt/resources/cloud-computing-dictionary/what-is-artificial-intelligence/?msockid=1ba5124451126d4f0d22076c50a36c8d#ve%C3%ADculos-de-condu%C3%A7%C3%A3o-aut%C3%B4noma. Acesso em: 16/11/2024.</p> </li> <li> <p>TECNOBLOG. Hist\u00f3ria da Intelig\u00eancia Artificial: Quem criou e como surgiu a tecnologia revolucion\u00e1ria. Dispon\u00edvel em: https://tecnoblog.net/responde/historia-da-inteligencia-artificial-quem-criou-e-como-surgiu-a-tecnologia-revolucionaria/. Acesso em: 16/11/2024.</p> </li> <li> <p>ICHI.PRO. Neur\u00f4nio McCulloch-Pitts: O Primeiro Modelo Matem\u00e1tico de um Neur\u00f4nio Biol\u00f3gico da Humanidade. Dispon\u00edvel em: https://ichi.pro/pt/neuronio-mcculloch-pitts-o-primeiro-modelo-matematico-de-um-neuronio-biologico-da-humanidade-105413088140753. Acesso em: 16/11/2024.</p> </li> <li> <p>LEMES, Nelson. Neur\u00f4nio de McCulloch-Pitts. UNIFAL-MG. Dispon\u00edvel em: https://pessoas.unifal-mg.edu.br/nelsonlemes/neuronio-de-mcculloch-pitts/#:~:text=Em%201943%2C%20W.%20McCulloch%20e%20W.%20Pitts%20desenvolveram,um%20para%20a%20teoria%20de%20Redes%20Neurais%20Artificiais. Acesso em: 16/11/2024.</p> </li> <li> <p>ACERVO LIMA. Tipos de Ambientes em IA. Dispon\u00edvel em: https://acervolima.com/tipos-de-ambientes-em-ia/#:~:text=Determin%C3%ADstico%20vs%20Estoc%C3%A1stico%20Quando%20uma%20exclusividade%20no%20estado,e%20n%C3%A3o%20pode%20ser%20completamente%20determinado%20pelo%20agente. Acesso em: 17/11/2024.</p> </li> <li> <p>AMAZON WEB SERVICES (AWS). O que s\u00e3o Agentes de IA? Dispon\u00edvel em: https://aws.amazon.com/pt/what-is/ai-agents/. Acesso em: 17/11/2024.</p> </li> <li> <p>ALL ABOUT AI. Tipos de Agentes de IA. Dispon\u00edvel em: https://www.allaboutai.com/pt-br/agentes-de-ia/tipos/. Acesso em: 17/11/2024.</p> </li> <li> <p>IBM THINK. Agentes de IA. Dispon\u00edvel em: https://www.ibm.com/br-pt/think/topics/ai-agents. Acesso em: 17/11/2024.</p> </li> </ul>"},{"location":"portifolios/portifolio2/","title":"Portif\u00f3lio 2","text":""},{"location":"portifolios/portifolio2/#portifolio-2","title":"Portif\u00f3lio 2","text":""},{"location":"portifolios/portifolio2/#inteligencia-artificial-resolvendo-problemas-por-busca","title":"Intelig\u00eancia Artificial - Resolvendo problemas por busca","text":"<p>\\vspace{10cm}</p> <p>Autor: Wildemberg Sales da Silva Junior</p> <p>Matr\u00edcula: 202017503</p> <p>Data: 24/12/2024</p> <p>Institui\u00e7\u00e3o/Universidade: Universidade de Bras\u00edlia(UnB)</p> <p>Disciplina: Intelig\u00eancia Artificial - FGA0221</p> <p>\\newpage</p>"},{"location":"portifolios/portifolio2/#resumo","title":"Resumo","text":"<p>Este artigo aborda temas relacionados a solu\u00e7\u00f5es de problemas por meio de buscas realizadas por agentes inteligentes. Foi explorado o que s\u00e3o agentes de resolu\u00e7\u00e3o de problemas e como eles atuam na busca de solu\u00e7\u00f5es, analisando as caracter\u00edsticas e propriedades dos ambientes em que esses modelos de agentes atuam. Tamb\u00e9m obtivemos uma vis\u00e3o geral sobre algoritmos de buscas, desde sistem\u00e1ticos, at\u00e9 em ambientes complexos, vendo suas aplica\u00e7\u00f5es em problemas reais, e explorando novos modelos de algoritmos n\u00e3o discutidos. Por fim, analisamos algoritmos gen\u00e9ticos que \u00e9 um pilar importante no conceito de busca por agentes.</p>"},{"location":"portifolios/portifolio2/#visao-geral","title":"Vis\u00e3o Geral","text":"<p>Este artigo traz informa\u00e7\u00f5es relevantes para o estudo de Intelig\u00eancia Artificial, pois aborda um tema muito utilizado no dia a dia que \u00e9 a busca, todos os dias realizamos diversos tipos de buscas e em diferentes situa\u00e7\u00f5es, ent\u00e3o entender esses tipos de agentes inteligentes e os modelos de algoritmos, agrega um valor muito valioso, pois expande o pensamento e a vis\u00e3o de implementa\u00e7\u00f5es em que pode ser utilizado esses agentes.</p> <p>\\newpage</p>"},{"location":"portifolios/portifolio2/#introducao","title":"Introdu\u00e7\u00e3o","text":"<p>Neste artigo, iremos abordar e discorrer sobre um t\u00f3pico importante da \u00e1rea de IA(Intelig\u00eancia Artificial) que ser\u00e3o os agentes de resolu\u00e7\u00e3o de problemas por meio de busca, em que vemos como um agente pode encontrar uma sequ\u00eancia de a\u00e7\u00f5es que alcan\u00e7a seus objetivos quando nenhuma a\u00e7\u00e3o isolada \u00e9 capaz de faz\u00ea-lo (RUSSEL; NORVIG, 2010).   No decorrer do artigo entenderemos o que s\u00e3o esses agentes de resolu\u00e7\u00e3o de problemas, os ambientes em que eles atuam, os problemas que s\u00e3o capazes de resolver, tipos de algoritmos de busca para resolu\u00e7\u00e3o de problemas em ambientes simples ou complexos, entre outros temas.  A seguir, iremos come\u00e7ar os nossos estudos entendendo o que s\u00e3o agentes de solu\u00e7\u00f5es de problemas, que ser\u00e1 o tema base para o nosso artigo.</p>"},{"location":"portifolios/portifolio2/#agente-de-resolucao-de-problemas","title":"Agente de resolu\u00e7\u00e3o de problemas","text":"<p>Agentes de resolu\u00e7\u00e3o de problemas s\u00e3o agentes baseados em objetivos que se diferenciam de agentes mais simples pelo fator de considerarem a\u00e7\u00f5es futuras e o quanto seus resultados s\u00e3o desej\u00e1veis. Outra caracter\u00edstica importante dos agentes de resolu\u00e7\u00e3o de problemas \u00e9 que eles se utilizam de representa\u00e7\u00f5es at\u00f4micas, onde os estados do mundo s\u00e3o considerados como um todo sem estrutura interna vis\u00edvel para os algoritmos (RUSSEL; NORVIG, 2010).</p> <p>\u00c9 importante entender que agentes inteligentes maximizam suas medidas de desempenho ao tomar decis\u00f5es baseadas na meta de atingir seu objetivo, com isso esses agentes simplificam seus problemas de decis\u00e3o ao definir um objetivo espec\u00edfico, tornando a resolu\u00e7\u00e3o de problemas mais f\u00e1cil de se gerenciar.  </p> <p>Um ponto que devemos entender \u00e9 a defini\u00e7\u00e3o de objetivos e a formula\u00e7\u00e3o de problemas realizadas pelos agentes, pois s\u00e3o a chave para a resolu\u00e7\u00e3o de problemas. Os objetivos s\u00e3o definidos como um conjunto de estados desejados no mundo, onde esses estados s\u00e3o os necess\u00e1rios para que o objetivo seja satisfeito, com isso o agente deve se verificar esses estados e entender como ele ir\u00e1 chegar no estado do objetivo, analisando as a\u00e7\u00f5es necess\u00e1rias e os estados intermedi\u00e1rios que levam ao estado objetivo. Com esses dados em an\u00e1lise o agente pode ent\u00e3o realizar a formula\u00e7\u00e3o do problema que vai fornecer uma vis\u00e3o geral para o agente sobre quais a\u00e7\u00f5es, decis\u00f5es e estados s\u00e3o os corretos e mais eficientes para alcan\u00e7ar o objetivo.</p> <p>Um agente pode ou n\u00e3o ter informa\u00e7\u00f5es dispon\u00edveis para tomar suas decis\u00f5es, com isso, se pensarmos em um agente que tem o objetivo de ir de um ponto A a um ponto B, e possui diversas rotas dispon\u00edveis para cumprir seu objetivo, se n\u00e3o possuir informa\u00e7\u00f5es sobre as rotas, o m\u00e9todo que ser\u00e1 adotado pelo agente \u00e9 tentar caminhos aleat\u00f3rios at\u00e9 cumprir o seu objetivo, mas, se o agente possuir informa\u00e7\u00f5es sobre as rotas como dist\u00e2ncia, sem\u00e1foros, desvios e etc, ele pode otimizar seu modo de agir, prevendo a\u00e7\u00f5es futuras e planejando uma sequ\u00eancia de a\u00e7\u00f5es otimizadas para chegar ao objetivo.</p> <p>Para que seja poss\u00edvel o agente poder analisar a\u00e7\u00f5es futuras, o ambiente em que o agente est\u00e1 inserido deve possuir as seguintes propriedades:</p> <ul> <li>Observ\u00e1vel: Onde o agente sempre conhece o estado atual;</li> <li>Discreto: Onde existe um n\u00famero finito de a\u00e7\u00f5es dispon\u00edveis em cada estado em que o agente se encontra; </li> <li>Conhecido: O agente sabe o resultado das a\u00e7\u00f5es que ele tomar;</li> <li>Determin\u00edstico: Cada a\u00e7\u00e3o que o agente tomar leva a um \u00fanico resultado;</li> </ul> <p>Com essas caracter\u00edsticas de ambientes bem definidas, \u00e9 poss\u00edvel afirmar que a solu\u00e7\u00e3o para um problema \u00e9 uma sequ\u00eancia fixa de a\u00e7\u00f5es  (RUSSEL; NORVIG, 2010). Vale ressaltar que essa premissa \u00e9 relacionada a ambientes previs\u00edveis, em ambiente menos previs\u00edveis, pode haver uma complexidade maior para chegar ao seu objetivo. Um agente que realiza seu planjamento de forma a ignorar o restante do ambiente, deve estar completamente certo do que est\u00e1 acontecendo, isso se chama de um sistema de malha aberta, pois ignorar a percep\u00e7\u00e3o quebra o la\u00e7o entre o agente e o ambiente.</p>"},{"location":"portifolios/portifolio2/#problemas-de-malha-aberta-e-de-malha-fechada","title":"Problemas de malha aberta e de malha fechada","text":"<p>Neste t\u00f3picos iremos abordar problemas de malha aberta e fechada, a fim de entender as diferen\u00e7as das a\u00e7\u00f5es de um agente nesses modelos.</p> <p>Antes de analisarmos os problemas, \u00e9 interessante entendermos a diferen\u00e7a entre malha aberta e malha fechada. </p> <ul> <li>Malha Aberta: Quando o agente executa o plano previamente definido com base nas informa\u00e7\u00f5es do ambiente, e executa o plano cegamente ignorando as novas percep\u00e7\u00f5es do ambiente, ou seja, ele n\u00e3o se adapta a novas altera\u00e7\u00f5es do ambiente;</li> <li>Malha Fechada: Quando o agente executa o planjedo, mas continua a observar o ambiente e se adaptar a ele, fazendo os ajustes em suas a\u00e7\u00f5es futuras.</li> </ul> <p>Com esses dois modelos definidos, podemos agora obervar um exemplo de problema com dois modelos, onde no exemplo 1.1 iremos analisar a resolu\u00e7\u00e3o do problema com malha aberta, e no exemplo 1.2 a resolu\u00e7\u00e3o do problema com malha fechada. Para basear os exemplos, o contexto ser\u00e1 o seguinte: </p> <p>Um agente pertencente a uma esteira de linha de montagem, deve realizar a montagem de um equipamento, para o agente \u00e9 fornecido um manual de intru\u00e7\u00f5es sobre a montagem de cada pe\u00e7a, e qual pe\u00e7a depende de outra.</p> <p>Exemplo 1.1 - Malha Aberta</p> <p>Se o agente executar suas a\u00e7\u00f5es em um modelo de malha aberta, ele ir\u00e1 analisar o documento fornecido com as intru\u00e7\u00f5es de montagem, as depend\u00eancias de pe\u00e7as, e qual a melhor ordem de montagem, com isso, ele ir\u00e1 tra\u00e7ar um plano para executar em ordem um conjunto de a\u00e7\u00f5es e chegar ao seu objetivo.</p> <p>Se n\u00e3o houver problem\u00e1ticas na montagem do equipamento, tudo ocorrer\u00e1 muito bem, e o agente ir\u00e1 conseguir terminar a montagem da maneira que planejou. Mas, se alguma pe\u00e7a do equipamento quebrar durante o processo e n\u00e3o servir para utiliza\u00e7\u00e3o, o agente n\u00e3o conseguir\u00e1 terminar sua montagem, pois ele n\u00e3o tem a capacidade de mudar seu planejamento devido a esse incidente.</p> <p>A seguir podemos ver a aplica\u00e7\u00e3o do algoritmo do agente:</p> <pre><code>ALGORITMO Montagem_Malha_Aberta\n    ENTRADA: instrucoes, pecas_disponiveis\n    PARA cada etapa EM instrucoes:\n        peca &lt;- etapa.peca\n        dependencias &lt;- etapa.dependencias\n\n        SE dependencias N\u00c3O EST\u00c3O em pecas_disponiveis:\n            EXIBIR \"Erro: Depend\u00eancias para a pe\u00e7a {peca} n\u00e3o est\u00e3o dispon\u00edveis.\"\n            ENCERRAR\n\n        SE peca N\u00c3O EST\u00c1 em pecas_disponiveis:\n            EXIBIR \"Erro: A pe\u00e7a {peca} est\u00e1 quebrada. N\u00e3o \u00e9 poss\u00edvel continuar.\"\n            ENCERRAR\n\n        REMOVER peca DE pecas_disponiveis\n        EXIBIR \"Montando a pe\u00e7a {peca}.\"\n\n    EXIBIR \"Montagem conclu\u00edda com sucesso.\"\nFIM_ALGORITMO\n</code></pre> C\u00f3digo 1: Algoritmo do agente executando em malha aberta. Fonte: OPENAI. Assistente Virtual ChatGPT, 2024 <p>Exemplo 1.2 - Malha Fechada</p> <p>Se o agente executar suas a\u00e7\u00f5es baseado no modelo de malha fechada, ele ir\u00e1 analisar o documento fornecido com as instru\u00e7\u00f5es de montagem, mas depenc\u00eancias das pe\u00e7as, e qual a melhor ordem de montagem para chegar ao objetivo da forma mais otimizada.</p> <p>Se n\u00e3o houver problem\u00e1ticas o agente conseguir\u00e1 chegar ao seu objetivo. Mas supondo que ocorra o mesmo problema do exemplo 1.1, onde durante a montagem uma das pe\u00e7as acabou se quebrando, o agente ir\u00e1 realizar uma nova an\u00e1lise das formas de contornar esse problema, seja solicitando uma nova pe\u00e7a para a esteira de produ\u00e7\u00e3o, ou ajustando seu plano para montar o equipamento sem e pe\u00e7a, ou deixando a montagem da pe\u00e7a quebrada para o final. Todas essas formas podem ser utilizadas pelo agente para continuar as a\u00e7\u00f5es para alcan\u00e7ar o objetivo, pois ele analisou os estados em que se encontrava e ajustou suas a\u00e7\u00f5es para isso.</p> <p>A seguir temos a aplica\u00e7\u00e3o do algoritmo do agente:</p> <pre><code>ALGORITMO Montagem_Malha_Fechada\n    ENTRADA: instrucoes, pecas_disponiveis\n    PARA cada etapa EM instrucoes:\n        peca &lt;- etapa.peca\n        dependencias &lt;- etapa.dependencias\n\n        ENQUANTO dependencias N\u00c3O EST\u00c3O em pecas_disponiveis:\n            EXIBIR \"Aguardando depend\u00eancias para a pe\u00e7a {peca}.\"\n            ADICIONAR dependencias PARA pecas_disponiveis\n\n        ENQUANTO peca N\u00c3O EST\u00c1 em pecas_disponiveis:\n            EXIBIR \"A pe\u00e7a {peca} est\u00e1 quebrada. Solicitando nova pe\u00e7a.\"\n            ADICIONAR peca PARA pecas_disponiveis\n\n        REMOVER peca DE pecas_disponiveis\n        EXIBIR \"Montando a pe\u00e7a {peca}.\"\n\n    EXIBIR \"Montagem conclu\u00edda com sucesso.\"\nFIM_ALGORITMO\n</code></pre> C\u00f3digo 2: Algoritmo do agente executando em malha fechada. Fonte: OPENAI. Assistente Virtual ChatGPT, 2024"},{"location":"portifolios/portifolio2/#algoritmos-de-busca","title":"Algoritmos de busca","text":"<p>Como foi visto anteriormente, agentes inteligentes fazem um planejamento para chegar ao seu objetivo, este planejamento \u00e9 feito baseado no entendimento do ambiente e atrav\u00e9s da previs\u00e3o se a\u00e7\u00f5es e estados futuros em que o agente pode estar, com isso, se nos aprofundarmos no planejamento das a\u00e7\u00f5es do agente, ser\u00e1 poss\u00edvel entender que \u00e9 composto por uma s\u00e9rie de buscas que analisam v\u00e1rias sequ\u00eancias de a\u00e7\u00f5es poss\u00edveis.</p> <p>Essas s\u00e9ries de buscas realizadas pelo agente que analisam diversas sequ\u00eancias de a\u00e7\u00f5es para identificar a melhor que chegar\u00e1 ao objetivo, acaba gerando uma \u00e1rvore de busca, onde tal \u00e1rvore possui na raiz o estado inicial do agente, em suas ramifica\u00e7\u00f5es existem as poss\u00edveis a\u00e7\u00f5es, e nos n\u00f3s os estados poss\u00edveis que o agente pode estar. Os agentes percorrem essas \u00e1rvores de busca diversas vezes para analisar e compreender qual a melhor \"rota\" poss\u00edvel para chegar ao objetivo.</p> <p>No decorrer desta se\u00e7\u00e3o iremos abordar dois importante t\u00f3picos de busca, a busca cega e a busca informada, que trazem aspectos e modelos diferentes de atua\u00e7\u00e3o de um agente na resolu\u00e7\u00e3o de um problema.</p>"},{"location":"portifolios/portifolio2/#busca-cega","title":"Busca Cega","text":"<p>A busca cega ou busca sem informa\u00e7\u00e3o, \u00e9 um modelo de busca realizado pelo agente, onde ele n\u00e3o tem nenhuma informa\u00e7\u00e3o adicional sobre os estados do ambiente, al\u00e9m das informa\u00e7\u00f5es que recebeu na defini\u00e7\u00e3o do problema, ou seja, ele n\u00e3o tem uma \"vis\u00e3o\" privilegiada sobre os estados mais promissores a serem explorados, portanto esses agentes funcionam apenas com a capacidade de gerar sucessores e distinguir se chegaram ao objetivo ou n\u00e3o.</p> <p>Dentro deste modelo de busca cega, temos alguns submodelos que possuem caracter\u00edsticas e funcionamentos diferentes, a seguir vamos entender um pouco mais sobre eles:</p> <ul> <li>Busca em Largura: Este modelo de busca expande todos os n\u00f3s da \u00e1rvore de busca, independente se durante o processo j\u00e1 encontrou o estado objetivo, ele segue um padr\u00e3o de abrir todos os n\u00f3s de um n\u00edvel, antes de expandir os n\u00f3s de outro n\u00edvel. Isso garante que o agente sempre encontre o melhor caminho para se chegar ao objetivo</li> <li>Busca de Custo Uniforme: Este modelo \u00e9 parecido com o de busca em largura, mas com uma pequena diferen\u00e7a, ele n\u00e3o expande todos os n\u00f3s de um n\u00edvel, ele expande os n\u00f3s com o menos custo de caminho, este modelo armazena atrav\u00e9s de uma fila de prioridade os custos e prioriza os de menor valor.</li> <li>Busca em Profundidade: Este modelo realiza um tipo de busca diferente dos citados anteriormente, ele realiza uma busca atrav\u00e9s de uma das ramifica\u00e7\u00f5es at\u00e9 chegar no objetivo ou ao final da ramifica\u00e7\u00e3o, caso ele encontre o final, ele volta um n\u00edvel, e abre as ramifica\u00e7\u00f5es. De forma mais simples, podemos pensar que ele vai sempre seguindo uma dire\u00e7\u00e3o da \u00e1rvore, por exemplo, em todo n\u00f3, ele sempre continua seguindo \u00e0 esquerda, at\u00e9 que chegue ao final ou ao objetivo, caso chegue ao final, ele volta um n\u00edvel, e come\u00e7a a pegar a direita, e assim por diante at\u00e9 percorrer toda a \u00e1rvore, ou at\u00e9 encontrar o objetivo. Uma diferen\u00e7a deste modelo para os anteriores, \u00e9 que ele n\u00e3o garante o melhor caminho at\u00e9 o objetivo.</li> <li>Busca de Bidirecional: Este modelo aplica uma l\u00f3gica de encontro de buscas, onde a sua busca \u00e9 iniciada em dois lugares, uma na raiz da \u00e1rvore e uma no objetivo, e essas buscas devem se encontrar em um caminho intermedi\u00e1rio.</li> <li>Busca de Profundidade Limitada: Este modelo \u00e9 o mesmo do de busca em profundidade, a diferen\u00e7a entre eles \u00e9 que este modelo tem um limite de n\u00edvel, onde caso ele chegue a esse limite, ele volta um n\u00edvel e contiua sua busca. De forma simples, \u00e9 como se fosse definido onde \u00e9 o \"final\" da \u00e1rvore.</li> </ul> <p>Agora que entendemos alguns dos modelos existentes de algoritmos de busca cega, podemos agora pensar em um exemplo onde a aplica\u00e7\u00e3o deste modelo pode ser eficiente.</p> <p>Exemplo: Imagine que temos um labirinto para percorrer, e neste labirinto h\u00e1 somente uma sa\u00edda, para isso temos um agente que ir\u00e1 percorrer o labirinto em busca da sa\u00edda. Podemos pensar de tr\u00eas modos com este problema, o primeiro onde o agente deve encontrar o melhor caminho para chegar a sa\u00edda, e o outro onde o agente deve encontrar a sa\u00edda o mais r\u00e1pido poss\u00edvel, nestes dois exemplos, podemos citar na mesma ordem tr\u00eas algoritmos para chegar a esses objetivos, o primeiro seria o de busca em largura para o primeiro objetivo de melhor caminho, onde o agente iria percorrer todas as rotas poss\u00edveis do labirinto para descobrir qual a melhor rota, e o segundo seria a de busca em profundidade e a busca bidirecional, onde o agente assim que encontrasse a sa\u00edda concluiria seu objetivo.</p> <p>A seguir no c\u00f3digo 3 podemos ver a implementa\u00e7\u00e3o do algoritmo de busca bidirecional, aplicado ao exemplo desenvolvido anteriormente.</p> <pre><code>from collections import deque\n\ndef bidirectional_search(labyrinth, start, goal):\n    def get_neighbors(position):\n        directions = [(0, 1), (1, 0), (0, -1), (-1, 0)]\n        neighbors = []\n        for dx, dy in directions:\n            nx, ny = position[0] + dx, position[1] + dy\n            if 0 &lt;= nx &lt; len(labyrinth) and 0 &lt;= ny &lt; len(labyrinth[0]) and labyrinth[nx][ny] != 1:\n                neighbors.append((nx, ny))\n        return neighbors\n\n    # Frontiers and visited sets for both searches\n    frontier_start = deque([start])\n    frontier_goal = deque([goal])\n    visited_start = {start: None}  # Keeps track of visited nodes and predecessors\n    visited_goal = {goal: None}\n\n    while frontier_start and frontier_goal:\n        # Expand the frontier from the start side\n        current_start = frontier_start.popleft()\n        for neighbor in get_neighbors(current_start):\n            if neighbor not in visited_start:\n                visited_start[neighbor] = current_start\n                frontier_start.append(neighbor)\n\n                if neighbor in visited_goal:  # Intersection found\n                    return reconstruct_path(neighbor, visited_start, visited_goal)\n\n        # Expand the frontier from the goal side\n        current_goal = frontier_goal.popleft()\n        for neighbor in get_neighbors(current_goal):\n            if neighbor not in visited_goal:\n                visited_goal[neighbor] = current_goal\n                frontier_goal.append(neighbor)\n\n                if neighbor in visited_start:  # Intersection found\n                    return reconstruct_path(neighbor, visited_start, visited_goal)\n\n    return None  # No path found\n\ndef reconstruct_path(meeting_point, visited_start, visited_goal):\n    # Reconstruct path from start to meeting point\n    path_start = []\n    current = meeting_point\n    while current is not None:\n        path_start.append(current)\n        current = visited_start[current]\n\n    # Reconstruct path from goal to meeting point\n    path_goal = []\n    current = visited_goal[meeting_point]\n    while current is not None:\n        path_goal.append(current)\n        current = visited_goal[current]\n\n    return path_start[::-1] + path_goal  # Combine both parts\n\n# Example labyrinth (0 = free space, 1 = wall)\nlabyrinth = [\n    [0, 0, 1, 0, 0],\n    [1, 0, 1, 0, 1],\n    [0, 0, 0, 0, 0],\n    [0, 1, 1, 1, 0],\n    [0, 0, 0, 1, 0]\n]\n\nstart = (0, 0)  # Starting point\ngoal = (4, 4)   # Goal point\n\npath = bidirectional_search(labyrinth, start, goal)\nif path:\n    print(\"Path found:\", path)\nelse:\n    print(\"No path found.\")\n\n</code></pre> C\u00f3digo 3: Implementa\u00e7\u00e3o do algoritmo de busca bidirecional aplicada ao exemplo anterior, Fonte: OPENAI. Assistente Virtual ChatGPT, 2024"},{"location":"portifolios/portifolio2/#busca-informada","title":"Busca Informada","text":"<p>A busca informada de acordo com RUSSEL e NORVIG, 2010, \u00e9 a que utiliza conhecimento de um problema espec\u00edfico al\u00e9m da defini\u00e7\u00e3o do problema em si \u2014 pode encontrar solu\u00e7\u00f5es de forma mais eficiente do que uma estrat\u00e9gia de busca sem informa\u00e7\u00e3o.</p> <p>Esse modelo de busca se d\u00e1 quando o agente tem informa\u00e7\u00f5es a mais sobre o ambiente e os estados que ele pode possuir ou possui, os modelos pertencente a busca informada se utilizam de fun\u00e7\u00f5es heur\u00edsticas, fun\u00e7\u00f5es para medi\u00e7\u00e3o do qu\u00e3o \"longe\" est\u00e1 um n\u00f3 da solu\u00e7\u00e3o, para avaliar os caminhos com o menos custo baseado nas informa\u00e7\u00f5es do problema. De forma simplificada podemos pensar na ideia de ir de uma cidade a outra com um mapa, onde o agente teria as informa\u00e7\u00f5es sobre os caminhos que ele pode percorrer como dist\u00e2ncia, desvios, problemas e etc, e baseado nessas informa\u00e7\u00f5es ele poderia calcular a rota com o menor custo para ele.</p> <p>A seguir iremos explorar alguns modelos de busca informada para entendermos melhor e nos aprofundarmos no assunto:</p> <ul> <li>Busca Gulosa de Melhor Escolha: Esse modelo se utiliza da fun\u00e7\u00e3o heur\u00edstica para escolher o pr\u00f3ximo n\u00f3 a ser expandido na \u00e1rvore de busca, se baseando nos n\u00f3s futuros que parecem estar mais pr\u00f3ximo do objetivo, n\u00e3o contabilizando o caminho j\u00e1 percorrido;</li> <li>Busca A*: Realiza a mesma fun\u00e7\u00e3o da busca gulosa, mas com um diferencial que \u00e9 a contabiliza\u00e7\u00e3o do caminho percorrido at\u00e9 o n\u00f3 atual, fazendo com que a fun\u00e7\u00e3o heur\u00edstica possua esse par\u00e2metro para o c\u00e1lculo do pr\u00f3ximo n\u00f3 a ser expandido; </li> <li>Busca Iterativa de Aprofundamento com A* (IDA*): Esse modelo \u00e9 uma varia\u00e7\u00e3o do A*, onde \u00e9 aplicado a ideia de limite de profundidade, onde o modelo realiza a busca at\u00e9 esse limite imposto, e se n\u00e3o encontrar o objetivo, ele modifica o limite para o menor valor da fun\u00e7\u00e3o heur\u00edstica j\u00e1 encontrado que excedeu o limite anterior, e repete sua busca;</li> <li>Busca Recursiva de Melhor Escolha (RBFS): Baseado no modelo de A*, se utiliza do mesmo princ\u00edpio, mas trabalha de modo recursivo em sua abordagem, fazendo com que toda vez que chegue em um limite de uma ramifica\u00e7\u00e3o, ele retorna e recalcula o limite.</li> <li>Busca Heur\u00edstica Bidirecional: Funciona de maneira similar a busca bidirecional de busca cega, onde s\u00e3o realizadas duas buscas simultaneamente, uma partindo da raiz e outra partindo do objetivo, e ambas as buscas utilizam heur\u00edsticas espec\u00edficas, para que ambas as buscas se encontrem no meio do \"caminho\".</li> </ul> <p>Agora que vimos alguns exemplos de modelos de busca informada, \u00e9 interessante explorarmos um exemplo para aprofundar o entendimento:</p> <p>Exemplo: Suponha que temos um jogo de tabuleiro, e esse jogo seja xadrez, jogos de tabuleiro como xadrez costumam ter a necessidade de bastante planejamento para as jogadas, avaliando as poss\u00edveis situa\u00e7\u00f5es e resultados que as a\u00e7\u00f5es podem causar. Com essa ideia em mente, seria poss\u00edvel aplicarmos um algoritmo de busca informada para jogar xadrez, basta entendermos que em um jogo de xadrez o agente iria possuir diversas informa\u00e7\u00f5es sobre o ambiente em que est\u00e1 atuando, poderia planejar jogadas baseadas nas jogadas do seu oponente, nas posi\u00e7\u00f5es das pe\u00e7as, entre outros diversos dados que iria possuir. Deste modo a aplica\u00e7\u00e3o de um algoritmo como o RBFS seria uma boa escolha para este caso, a seguir no c\u00f3digo 4 podemos ver uma vers\u00e3o simplificada da ideia do tabuleiro de xadrez.</p> <pre><code>import chess\n\ndef heuristic(board):\n    \"\"\"Avalia o tabuleiro com base no material de cada lado.\"\"\"\n    piece_values = {\n        chess.PAWN: 1,\n        chess.KNIGHT: 3,\n        chess.BISHOP: 3,\n        chess.ROOK: 5,\n        chess.QUEEN: 9,\n        chess.KING: 1000\n    }\n    score = 0\n    for piece_type in piece_values:\n        score += len(board.pieces(piece_type, chess.WHITE)) * piece_values[piece_type]\n        score -= len(board.pieces(piece_type, chess.BLACK)) * piece_values[piece_type]\n    return score\n\ndef rbfs(board, depth, alpha, beta, is_white):\n    \"\"\"\n    Recursive Best-First Search (RBFS) para o xadrez.\n    - board: o tabuleiro atual.\n    - depth: a profundidade m\u00e1xima de busca.\n    - alpha, beta: os limites alfa-beta.\n    - is_white: indica se \u00e9 o turno do jogador branco.\n    \"\"\"\n    if board.is_checkmate():\n        return float('inf') if is_white else float('-inf'), None\n    if board.is_stalemate() or board.is_insufficient_material() or depth == 0:\n        return heuristic(board), None\n\n    best_score = float('-inf') if is_white else float('inf')\n    best_move = None\n\n    for move in board.legal_moves:\n        board.push(move)\n        score, _ = rbfs(board, depth - 1, alpha, beta, not is_white)\n        board.pop()\n\n        if is_white:\n            if score &gt; best_score:\n                best_score, best_move = score, move\n            alpha = max(alpha, score)\n        else:\n            if score &lt; best_score:\n                best_score, best_move = score, move\n            beta = min(beta, score)\n\n        if beta &lt;= alpha:\n            break\n\n    return best_score, best_move\n\n# Configura\u00e7\u00e3o inicial do tabuleiro\nboard = chess.Board()\n\n# Simula\u00e7\u00e3o de uma jogada usando RBFS\ndepth = 3  # Profundidade de busca limitada\nis_white_turn = True\nscore, move = rbfs(board, depth, float('-inf'), float('inf'), is_white_turn)\n\nprint(\"Melhor movimento sugerido:\", move)\nif move:\n    board.push(move)\n    print(board)\n</code></pre> C\u00f3digo 4: Implementa\u00e7\u00e3o do algoritmo de busca RBFS aplicada ao exemplo anterior, Fonte: OPENAI. Assistente Virtual ChatGPT, 2024"},{"location":"portifolios/portifolio2/#busca-em-ambientes-complexos","title":"Busca em ambientes complexos","text":"<p>At\u00e9 o presente momento, vimos diversos algoritmos de buscas sistem\u00e1ticos que se preocupavam em alcan\u00e7ar o seu objetivo descobrindo um caminho para chegar nele, mas agora, iremos ver um outro modelo de busca, que atuam em ambientes complexos, onde a preocupa\u00e7\u00e3o n\u00e3o ser\u00e1 o caminho para chegar, mas sim se os estados atuais est\u00e3o de acordo com o objetivo.</p> <p>Um dos modelos de busca que atua dentro de ambientes complexos, \u00e9 o de busca local, esse algoritmo n\u00e3o se preocupa com estados anteriores, ou seja, n\u00e3o grava a rota percorrida, economizando mem\u00f3ria, ele se foca somente no estado atual, analisando e se deslocando para os estados vizinhos em preocupa\u00e7\u00e3o com os estados anteriores. Uma das grandes vantagens da busca local, al\u00e9m de economizar mem\u00f3ria e atuarem muito bem em grandes ou infinitos ambientes, eles tamb\u00e9m ajudam a resolver problemas de otimiza\u00e7\u00e3o, nos quais o objetivo \u00e9 encontrar o melhor estado de acordo com a fun\u00e7\u00e3o objetivo (RUSSEL; NORVIG, 2010).</p> <p>Neste ambito de busca local, podemos observar alguns dos diversos modelos de buscas existes, a seguir iremos entender um pouco mais os algoritmos escolhidos:</p> <ul> <li>Busca de Subida de Encosta: Um dos modelos de busca local mais simples, onde durante o seu processo de busca do objetivo, ele tenta melhorar constantemente e progressivamente a solu\u00e7\u00e3o atual, ele come\u00e7a em um estado aleat\u00f3rio ou definido, e durante sua \"jornada\" sempre tenta escolher o melhor vizinho baseado no valor da fun\u00e7\u00e3o objetivo, onde dependendo do problema pode ser o maior valor ou o menor valor;</li> <li>T\u00eampera Simulada: \u00c9 um modelo completo mas ineficiente, sua l\u00f3gica \u00e9 baseada em movimentos \"aleat\u00f3rios\" onde ele fica em um processo de subida e descida nos valores da fun\u00e7\u00e3o objetivo, se o movimento realizado melhorar a situa\u00e7\u00e3o do agente, esse movimento sempre ser\u00e1 aceito, se n\u00e3o, o modelo ir\u00e1 aceitar o modelo ap\u00f3s uma an\u00e1lise na probabilidade de melhora;</li> <li>Busca em Feixe Local: Este modelo \u00e9 baseado na busca em largura, mas com um foco diferente, ele busca explorar um n\u00famero de estados maior em cada n\u00edvel, e aos inv\u00e9s de explorar todos os n\u00f3s de um n\u00edvel, ele seleciona apenas os melhores n\u00f3s, e com isso limita a quantidade de estados.</li> </ul> <p>Para entendermos melhor como esses algoritmos podem funcionar, vamos trazer um exemplo e a aplica\u00e7\u00e3o de um desses modelos para a solu\u00e7\u00e3o do problema:</p> <p>Exemplo: Imagine que um agente \u00e9 respons\u00e1vel por fazer a organiza\u00e7\u00e3o de um armaz\u00e9m, ele tem diversos produtos e precisa organiz\u00e1-los de uma forma otimizada para facilitar o processo de coleta e transporte desse produto, a aplica\u00e7\u00e3o de um algoritmo de Subida de Enconsta pode ajudar, onde durante suas an\u00e1lises ele tentar\u00e1 achar a melhor e mais eficiente solu\u00e7\u00e3o.</p> <p>A seguir no c\u00f3digo 5, podemos ver a implementa\u00e7\u00e3o deste exemplo em python.</p> <pre><code>import random\n\n# Fun\u00e7\u00e3o que calcula a dist\u00e2ncia total percorrida para pegar todos os produtos (simula\u00e7\u00e3o simples)\ndef calcular_distancia(arranjo):\n    # Aqui a dist\u00e2ncia \u00e9 simplesmente a soma das dist\u00e2ncias entre produtos consecutivos\n    distancia = 0\n    for i in range(len(arranjo) - 1):\n        distancia += abs(arranjo[i] - arranjo[i+1])  # Dist\u00e2ncia entre posi\u00e7\u00f5es consecutivas\n    return distancia\n\n# Fun\u00e7\u00e3o para gerar um estado vizinho (movendo dois produtos de lugar)\ndef gerar_vizinho(arranjo):\n    novo_arranjo = arranjo[:]\n    i, j = random.sample(range(len(arranjo)), 2)  # Seleciona dois \u00edndices aleat\u00f3rios\n    novo_arranjo[i], novo_arranjo[j] = novo_arranjo[j], novo_arranjo[i]  # Troca os produtos\n    return novo_arranjo\n\n# Algoritmo de Subida de Encosta (Hill Climbing)\ndef subida_de_encosta(arranjo_inicial):\n    estado_atual = arranjo_inicial\n    custo_atual = calcular_distancia(estado_atual)\n\n    while True:\n        # Gerar um vizinho e calcular seu custo\n        vizinho = gerar_vizinho(estado_atual)\n        custo_vizinho = calcular_distancia(vizinho)\n\n        # Se o vizinho for melhor (menor custo), mova para ele\n        if custo_vizinho &lt; custo_atual:\n            estado_atual = vizinho\n            custo_atual = custo_vizinho\n        else:\n            # Se n\u00e3o encontrar melhorias, termina o algoritmo\n            break\n\n    return estado_atual, custo_atual\n\n# Exemplo de uso\n# Inicializando o arranjo de produtos no armaz\u00e9m (ex: posi\u00e7\u00f5es em um eixo linear)\narranjo_inicial = [4, 2, 8, 1, 6, 5, 7, 3]\n\n# Rodando o algoritmo de subida de encosta\nmelhor_arranjo, custo_final = subida_de_encosta(arranjo_inicial)\n\n# Exibindo o melhor arranjo e o custo final\nprint(f\"Melhor arranjo encontrado: {melhor_arranjo}\")\nprint(f\"Custo final (dist\u00e2ncia total): {custo_final}\")\n</code></pre> C\u00f3digo 5: Implementa\u00e7\u00e3o do algoritmo de busca de Subida de Enconsta aplicada ao exemplo anterior, Fonte: OPENAI. Assistente Virtual ChatGPT, 2024"},{"location":"portifolios/portifolio2/#algoritmos-geneticos","title":"Algoritmos gen\u00e9ticos","text":"<p>Os algoritmos gen\u00e9ticos s\u00e3o uma varia\u00e7\u00e3o da busca em feixe estoc\u00e1stica na qual os estados sucessores s\u00e3o gerados pela combina\u00e7\u00e3o de dois estados pais, em vez de serem gerados pela modifica\u00e7\u00e3o de um \u00fanico estado (RUSSEL; NORVIG, 2010).</p> <p>Esses algoritmos gen\u00e9ticos funcionam da seguinte forma, eles possuem um conjunto de estados, onde nesses estados eles avaliam os mais potenciais a resolver a solu\u00e7\u00e3o, e fazem combina\u00e7\u00f5es para gerarem novos estados baseados nos anteriores (como se fosse a reprodu\u00e7\u00e3o sexuada, por isso algortimo gen\u00e9tico). O processo de avalia\u00e7\u00e3o \u00e9 feito baseado em uma fun\u00e7\u00e3o de avalia\u00e7\u00e3o que analisa cada estado, fornece um valor para os estados, e em seguida identifica o que aparenta ser a melhor escolha para realizar a combina\u00e7\u00e3o.</p> <p>A seguir, iremos ver um exemplo para podermos absorver a ideia de algoritmos gen\u00e9ticos de forma mais tranquila.</p> <p>Exemplo: Baseado no problema da mochila, pertencente ao \"Os 21 problemas NP-completos, que foram introduzidos por Richard Karp em 1972 como forma de demonstrar a aplicabilidade do conceito de NP-completude\" (WIKIPEDIA, 2024). Temos uma mochila com peso limitado, e uma s\u00e9rie de itens que possuem peso e valor, com isso, temos de selecionar de maneira inteligente, os item de maior valor, sem exceder a capacidade de peso da mochila. O algoritmo ir\u00e1 analisar as combina\u00e7\u00f5es poss\u00edveis e retornar um resultado para o problema.</p> <p>Podemos ver a aplica\u00e7\u00e3o deste exemplo no c\u00f3digo 6.</p> <pre><code>def knapsack(values, weights, capacity):\n    \"\"\"\n    Resolve o problema da mochila utilizando programa\u00e7\u00e3o din\u00e2mica.\n\n    :param values: Lista dos valores dos itens.\n    :param weights: Lista dos pesos dos itens.\n    :param capacity: Capacidade m\u00e1xima da mochila.\n    :return: Valor m\u00e1ximo que pode ser colocado na mochila e os itens escolhidos.\n    \"\"\"\n    n = len(values)\n    # Matriz para armazenar os valores m\u00e1ximos para cada capacidade e n\u00famero de itens.\n    dp = [[0] * (capacity + 1) for _ in range(n + 1)]\n\n    # Preenchendo a matriz dp\n    for i in range(1, n + 1):\n        for w in range(1, capacity + 1):\n            if weights[i - 1] &lt;= w:\n                # Inclui o item i-1 ou n\u00e3o\n                dp[i][w] = max(dp[i - 1][w], values[i - 1] + dp[i - 1][w - weights[i - 1]])\n            else:\n                dp[i][w] = dp[i - 1][w]\n\n    # Determinando os itens escolhidos\n    chosen_items = []\n    w = capacity\n    for i in range(n, 0, -1):\n        if dp[i][w] != dp[i - 1][w]:  # Se o valor mudou, significa que o item foi inclu\u00eddo\n            chosen_items.append(i - 1)\n            w -= weights[i - 1]\n\n    return dp[n][capacity], chosen_items\n\n\n# Exemplo de uso\nvalues = [60, 100, 120]  # Valores dos itens\nweights = [10, 20, 30]   # Pesos dos itens\ncapacity = 50            # Capacidade m\u00e1xima da mochila\n\nmax_value, items = knapsack(values, weights, capacity)\n\nprint(\"Valor m\u00e1ximo:\", max_value)\nprint(\"Itens escolhidos:\", items)\n\n</code></pre> C\u00f3digo 6: Implementa\u00e7\u00e3o do algoritmo de busca gen\u00e9tica aplicada ao exemplo anterior, Fonte: OPENAI. Assistente Virtual ChatGPT, 2024"},{"location":"portifolios/portifolio2/#conclusao","title":"Conclus\u00e3o","text":"<p>Baseado em tudo que estudamos neste artigo, foi poss\u00edvel entender diversos t\u00f3picos importantes para o entendimento sobre a solu\u00e7\u00e3o de problemas por buscas, conseguimos obter um entendimento sobre como agentes atuam atrav\u00e9s de diferentes modelos de busca, desde buscas sistem\u00e1ticas, at\u00e9 buscas em ambientes complexos, com exemplos claros de sua utiliza\u00e7\u00e3o e aplica\u00e7\u00e3o em linguagem python. Por fim aprofundamos nosso assunto de busca em um conceito importante que \u00e9 a busca por algoritmo gen\u00e9tico que tem suas aplica\u00e7\u00f5es em diversos setores importantes.</p>"},{"location":"portifolios/portifolio2/#referencias","title":"Refer\u00eancias","text":"<p>[1] RUSSELL, Stuart; NORVIG, Peter. Intelig\u00eancia Artificial: Uma Abordagem Moderna \u2013 3\u00aa edi\u00e7\u00e3o. [2] OPENAI. Assistente Virtual ChatGPT. Respostas geradas com base em intelig\u00eancia artificial. Dispon\u00edvel em: https://openai.com. Acesso em: 24 dez. 2024. [3] WIKIPEDIA. 21 problemas NP-completos de Karp. Dispon\u00edvel em: https://pt.wikipedia.org/wiki/21_problemas_NP-completos_de_Karp. Acesso em: 29 dez. 2024.</p>"},{"location":"portifolios/portifolio3/","title":"Portif\u00f3lio 3","text":""},{"location":"portifolios/portifolio3/#portifolio-3","title":"Portif\u00f3lio 3","text":""},{"location":"portifolios/portifolio3/#inteligencia-artificial-problemas-de-satisfacao-de-condicoes-csps","title":"Intelig\u00eancia Artificial - Problemas de Satisfa\u00e7\u00e3o de Condi\u00e7\u00f5es (CSPs)","text":"<p>\\vspace{10cm}</p> <p>Autor: Wildemberg Sales da Silva Junior</p> <p>Matr\u00edcula: 202017503</p> <p>Data: 30/12/2024</p> <p>Institui\u00e7\u00e3o/Universidade: Universidade de Bras\u00edlia(UnB)</p> <p>Disciplina: Intelig\u00eancia Artificial - FGA0221</p> <p>\\newpage</p>"},{"location":"portifolios/portifolio3/#resumo","title":"Resumo","text":"<p>Este artigo aborda a resolu\u00e7\u00e3o de problemas por meio da satisfa\u00e7\u00e3o de condi\u00e7\u00f5es, que \u00e9 um modelo diferente da busca tradicional, onde os agentes deixam de se importar somente com o estado objetivo do resultado, e agora observam os conjuntos de vari\u00e1veis que possuem valores espec\u00edficos. Durante a explora\u00e7\u00e3o deste problemas de satisfa\u00e7\u00e3o de condi\u00e7\u00f5es, tamb\u00e9m foram aprofundados assuntos realcionados ao entendimento da estruturas de problemas, analisamos os tipos de condi\u00e7\u00f5es que um problema pode possuir e os modelos de consist\u00eancia que garante que haja uma solu\u00e7\u00e3o para o problema. Tamb\u00e9m foram explorados alguns algoritmos que podem ser utilizados para encontrar a solu\u00e7\u00e3o de problemas deste porte, apresentando exemplos concretos em que eles podem ser utilizados.</p>"},{"location":"portifolios/portifolio3/#visao-geral","title":"Vis\u00e3o Geral","text":"<p>O artigo tratou de temas relevantes e interessantes que trouxeram uma vis\u00e3o diferente de como agentes podem solucionar problemas mais complexos al\u00e9m da busca tradicional. Temas como tipo de condi\u00e7\u00f5es aumentou ainda mais o entendimento sobre as estruturas que um problema pode ter, e a introdu\u00e7\u00e3o sobre consist\u00eancia mostrou como \u00e9 poss\u00edvel garantir que um problema possua solu\u00e7\u00e3o baseado em suas condi\u00e7\u00f5es.</p> <p>\\newpage</p>"},{"location":"portifolios/portifolio3/#introducao","title":"Introdu\u00e7\u00e3o","text":"<p>Neste artigo abordaremos uma vers\u00e3o diferentes de resolu\u00e7\u00e3o de problemas por agentes inteligentes, que ser\u00e1 a resolu\u00e7\u00e3o de problemas por meio da satisfa\u00e7\u00e3o de condi\u00e7\u00f5es (CSPs). </p> <p>Sabemos que existe a resolu\u00e7\u00e3o por meio de buscas que os agentes realizam, onde seu objetivo \u00e9 avaliar os estados em que \"trafegam\" para encontrar o estado objetivo, esses agentes utilizam avalia\u00e7\u00f5es heur\u00edsiticas espec\u00edficas de dom\u00ednios para descobrirem se est\u00e3o ou n\u00e3o no estado objetivo. Durante essas buscas, os agentes inteligentes consideram cada estado como at\u00f4mico, n\u00e3o se importando com as caracter\u00edsticas do estado. Neste novo modelo que iremos explorar, essa \"vis\u00e3o\" do agente muda em rela\u00e7\u00e3o aos estados.</p> <p>No modelo em que os agentes exploram a resolu\u00e7\u00e3o de problemas por satisfa\u00e7\u00e3o de condi\u00e7\u00e3o, eles deixam de considerar cada estado at\u00f4mico, e come\u00e7am a avaliar as vari\u00e1veis de cada estado, com isso, eles come\u00e7am a entender que um problema foi resolvido, quando cada vari\u00e1vel tiver um valor que satisfa\u00e7a todas as condi\u00e7\u00f5es impostas do problema.</p>"},{"location":"portifolios/portifolio3/#representacao-atomica-vs-fatorada","title":"Representa\u00e7\u00e3o At\u00f4mica vs. Fatorada","text":"<p>Como dito anteriormente, os agentes inteligentes quando utilizam a resolu\u00e7\u00e3o de problemas por satisfa\u00e7\u00e3o de condi\u00e7\u00e3o, ele deixam de considerar a representa\u00e7\u00e3o dos estados de forma at\u00f4mica, e come\u00e7am a avaliar uma representa\u00e7\u00e3o fatorada dos estados, onde \u00e9 considerado as vari\u00e1veis do estado, e o problema s\u00f3 \u00e9 resolvido quando todas as vari\u00e1veis possuem os valores que atendam as condi\u00e7\u00f5es (RUSSEL; NORVIG, 2010).</p>"},{"location":"portifolios/portifolio3/#definindo-problemas-de-satisfacao-de-condicoes","title":"Definindo Problemas de Satisfa\u00e7\u00e3o de Condi\u00e7\u00f5es","text":"<p>Agora que entendemos como os agentes agem quando se trata de problemas de satisfa\u00e7\u00e3o de condi\u00e7\u00f5es, agora devemos entender o que s\u00e3o esses problemas e suas principais caracter\u00edsticas. </p> <p>De acordo com Russel e Norvig, 2010, um problema de satisfa\u00e7\u00e3o de condi\u00e7\u00e3o consiste em tr\u00eas componentes, X, D, e C, onde cada um representa:</p> <ul> <li>X: conjunto de vari\u00e1veis, {X1, ..., Xn};</li> <li>D: conjunto de dom\u00ednio de cada vari\u00e1vel (valores que pode obter), {D1, ..., Dn};</li> <li>C: conjunto de restri\u00e7\u00f5es que especificam as poss\u00edveis combina\u00e7\u00f5es de valores poss\u00edveis. Cada restri\u00e7\u00e3o \u00e9 uma par de escopo e rel, onde escopo \u00e9 a tupla de vari\u00e1veis que participam da combina\u00e7\u00e3o, e rel \u00e9 a rela\u00e7\u00e3o que define os valores que as vari\u00e1veis podem assumir, onde cada rel pode ser representado por uma lista de tuplas v\u00e1lidas ou abstratas por meio de condi\u00e7\u00f5es;</li> </ul> <p>Portanto, para resolver um problema de satisfa\u00e7\u00e3o de condi\u00e7\u00e3o \u00e9 necess\u00e1rios definirmos um conjunto de estados e a no\u00e7\u00e3o de solu\u00e7\u00e3o. Onde cada estado \u00e9 definido por uma atribui\u00e7\u00e3o de valores a alguma ou todas as vari\u00e1veis (RUSSEL; NORVIG, 2010). As atribui\u00e7\u00f5es podem ter diferentes formas:</p> <ul> <li>Atribui\u00e7\u00e3o consistente: \u00e9 uma atribui\u00e7\u00e3o que n\u00e3o viola qualquer condi\u00e7\u00e3o;</li> <li>Atribui\u00e7\u00e3o completa: quando todas as vari\u00e1veis recebem uma atribui\u00e7\u00e3o;</li> <li>Atribui\u00e7\u00e3o parcial: quando somente algumas vari\u00e1veis recebem valores;</li> </ul> <p>Baseado nas atribui\u00e7\u00f5es chegamos a uma solu\u00e7\u00e3o, que pode ser descrita como uma atribui\u00e7\u00e3o consistente e completa.</p> <p>Para ficar mais claro a ideia de problemas que podem ser resolvidos baseado na satisfa\u00e7\u00e3o de condi\u00e7\u00f5es, podemos ver um exemplo baseado no ambiente acad\u00eamico:</p> <p>Exemplo: Dentro de um ambiente acad\u00eamico como a Universidade de Bras\u00edlia (UnB), os alunos necessitam montar sua grade de hor\u00e1rio e mat\u00e9rias todo o semestre, com isso podemos colocar essa problematica para um agente resolver, modelando o problema da seguinte forma:</p> <ul> <li>Problema: Criar uma grade hor\u00e1ria de mat\u00e9rias para o semestre:</li> <li>Condi\u00e7\u00f5es (C): N\u00e3o pode ter duas mat\u00e9rias no mesmo hor\u00e1rio e o aluno tem que ter permiss\u00e3o para se matricular nessa mat\u00e9ria;</li> <li>Vari\u00e1veis (X): Cada Mat\u00e9ria;</li> <li>Dom\u00ednios (D): Hor\u00e1rios dispon\u00edveis de cada mat\u00e9ria, e permiss\u00f5es do aluno;</li> </ul> <p>Desta forma o agente poderia agir sobre essa estrutura para se chegar a uma solu\u00e7\u00e3o.</p>"},{"location":"portifolios/portifolio3/#tipos-de-condicoes","title":"Tipos de Condi\u00e7\u00f5es","text":"<p>Al\u00e9m de entendermos as vari\u00e1veis que comp\u00f5em um problema, tamb\u00e9m \u00e9 poss\u00edvel explorar os tipos de condi\u00e7\u00f5es que fazem parte do problema. A seguir temos os tipos de condi\u00e7\u00f5es e aplica\u00e7\u00f5es baseadas no exemplo anterior, de cada um tipo para aprofundamos o conhecimento:</p> <ul> <li>Unit\u00e1ria: Quando restringe o valor de somente uma vari\u00e1vel. No exemplo anterior o agente teria que escolher turmas para hor\u00e1rios diferentes, se aplicarmos uma regra onde ele n\u00e3o pode colocar no hor\u00e1rio de 14h, seria uma restri\u00e7\u00e3o unit\u00e1ria;</li> <li>Bin\u00e1ria: As condi\u00e7\u00f5es bin\u00e1rias relacionam duas vari\u00e1veis. No exemplo anterior o agente n\u00e3o poderia colocar duas mat\u00e9rias no mesmo hor\u00e1rio, ou seja, Hor\u00e1rio_Tuma_A != Hor\u00e1rio_Turma_B;</li> <li>Tern\u00e1ria: A condi\u00e7\u00e3o tern\u00e1ria de d\u00e1 quando relacionamos tr\u00eas vari\u00e1veis, ou seja, a Turma_C deve estar entra a Turma_A e a Turma_B;</li> <li>Global: Essa condi\u00e7\u00e3o se d\u00e1 quando se envolve um n\u00famero arbitr\u00e1rio de vari\u00e1veis, n\u00e3o necessariamente todas, portanto, aplicando no exemplo anterior, podemos dizer que as mat\u00e9rias devem ter professores diferentes para cada;</li> </ul> <p>Os algoritmos de solu\u00e7\u00e3o dos CSPs, pode realizar duas a\u00e7\u00f5es, eles podem buscar onde ele vai escolher uma nova atribui\u00e7\u00e3o para a vari\u00e1vel de v\u00e1rias possibilidades, ou ele pode fazer uma infer\u00eancia chamada propaga\u00e7\u00e3o de condi\u00e7\u00f5es, onde ele reduz o n\u00famero de valores poss\u00edveis para a vari\u00e1vel atual, e como consequ\u00eancia, ele reduz sucessivamente os poss\u00edveis valores das vari\u00e1veis seguintes, garantindo uma consist\u00eancia local.</p>"},{"location":"portifolios/portifolio3/#consistencia","title":"Consist\u00eancia","text":"<p>Como dito anteriormente \u00e9 poss\u00edvel gerar uma consist\u00eancia dentro dos problemas que abordamos, com isso, iremos explorar os tipos de consist\u00eancias poss\u00edveis que pode ser gerado.</p> <ul> <li>N\u00f3: Para a consist\u00eancia de n\u00f3 (n\u00f3-consistente), \u00e9 necess\u00e1rio que todos os valores de seu dom\u00ednio respeitem a condi\u00e7\u00e3o un\u00e1ria da vari\u00e1vel, com isso, \u00e9 eliminado todos os dom\u00ednios que n\u00e3o atendem a condi\u00e7\u00e3o;</li> <li>Arco: Para a consist\u00eancia de arco (arco-consistente), \u00e9 necess\u00e1rios que os valores do dom\u00ednio satisfa\u00e7am as restri\u00e7\u00f5es bin\u00e1rias da vari\u00e1vel;</li> <li>Trajeto: A consist\u00eancia de trajeto \u00e9 aplicada quando fixa as restri\u00e7\u00f5es bin\u00e1rias para garantir a consist\u00eancia em um trajeto de tr\u00eas vari\u00e1veis;</li> <li>K: A consist\u00eancia em K \u00e9 definida quando em um conjunto de K-1 vari\u00e1veis, e para qualquer atribui\u00e7\u00e3o a essas vari\u00e1veis, um valor consistente puder ser atribuido a qualquer uma das vari\u00e1veis do conjunto de K;</li> <li>Globais: Na consist\u00eancia global, ela deve ser K-consist\u00eante para quase todas ou todas as K vari\u00e1veis que fazem parte do conjunto, onde por mais que seja global, n\u00e3o implica que necessariamente ser\u00e3o todas.</li> </ul>"},{"location":"portifolios/portifolio3/#algoritmos","title":"Algoritmos","text":"<p>Dentro do campo de implementa\u00e7\u00e3o dos agentes que realizam a solu\u00e7\u00e3o de problemas por satisfa\u00e7\u00e3o de busca, podemos come\u00e7ar a citar alguns algoritmos e suas aplica\u00e7\u00f5es. A seguir iremos explorar alguns algoritmos comumente utilizados.</p>"},{"location":"portifolios/portifolio3/#ac-3","title":"AC-3","text":"<p>O algoritmo AC-3 examina os arcos existentes atrav\u00e9s de pares de vari\u00e1veis (X e Y), com isso ele vai removendo os dom\u00ednios de X que n\u00e3o seguem as restri\u00e7\u00f5es impostas pro par. O algoritmo vai mantendo em mem\u00f3ria as cole\u00e7\u00f5es de arcos que ainda n\u00e3o foram verificados, ent\u00e3o quando um dom\u00ednio de uma vari\u00e1vel \u00e9 retirado, todos os arcos que tem rela\u00e7\u00e3o de restri\u00e7\u00f5es com o dom\u00ednio s\u00e3o adicionados a cole\u00e7\u00e3o, menos aquele que est\u00e1 na restri\u00e7\u00e3o atual (WIKIPEDIA, 2024).</p> <p>A seguir, no c\u00f3digo 1, podemos ver a implementa\u00e7\u00e3o do pseudo-c\u00f3digo do AC-3:</p> <pre><code>AC-3(CSP):\n  1. Inicialize a fila Q com todos os arcos (Xi, Xj) das restri\u00e7\u00f5es do CSP.\n  2. Enquanto Q n\u00e3o estiver vazia:\n      3. Remova um arco (Xi, Xj) de Q.\n      4. Se REMOVER_VALORES_INCONSISTENTES(Xi, Xj):\n          5. Para cada vari\u00e1vel Xk adjacente a Xi (exceto Xj):\n              Adicione (Xk, Xi) \u00e0 fila Q.\n  6. Retorne True (todos os arcos s\u00e3o consistentes) ou False (algum dom\u00ednio ficou vazio).\n\nREMOVER_VALORES_INCONSISTENTES(Xi, Xj):\n  1. Inicialize alterado = False.\n  2. Para cada valor vi em Di:\n      3. Se n\u00e3o existe valor vj em Dj que satisfa\u00e7a a restri\u00e7\u00e3o entre Xi e Xj:\n          4. Remova vi de Di.\n          5. alterado = True.\n  6. Retorne alterado.\n</code></pre> C\u00f3digo 1: Implementa\u00e7\u00e3o em pseudo-c\u00f3digo do algoritmo AC-3, Fonte: OPENAI. Assistente Virtual ChatGPT, 2024 <p>Podemos analisar um exemplo para esse algoritmo:</p> <p>Exemplo: Um professor ir\u00e1 aplicar uma prova para sua turma, ele conhece muito bem seus alunos e quer aloc\u00e1-los em suas cadeiras, ele entende que alguns alunos n\u00e3o podem ficar juntos pois pode haver cola durante a prova, cada cadeira s\u00f3 pode ter um aluno, e alguns alunos tem a necessidade de sentar em lugares espec\u00edficos. Se aplicassemos o algoritmo para ajudar com esse problema, iriamos obter um um conjunto de dom\u00ednios que atendem as condi\u00e7\u00f5es.</p>"},{"location":"portifolios/portifolio3/#backtracking","title":"Backtracking","text":"<p>O Backtracking \u00e9 um modelo de busca de profundidade que escolhe valores para todas as v\u00e1ri\u00e1veis do problema, uma vari\u00e1vel de cada vez, e que realiza o retrocesso quando n\u00e3o h\u00e1 valores v\u00e1lidos restantes para serem atribuidos a uma vari\u00e1vel (RUSSEL; NORVIG, 2010).</p> <p>A seguir no c\u00f3digo 2, podemos ver a implementa\u00e7\u00e3o do algoritmo em pseudo-c\u00f3digo:</p> <pre><code>BACKTRACKING(CSP, atribui\u00e7\u00e3o):\n  1. Se todas as vari\u00e1veis est\u00e3o atribu\u00eddas:\n      Retorne atribui\u00e7\u00e3o.\n  2. Escolha uma vari\u00e1vel n\u00e3o atribu\u00edda X.\n  3. Para cada valor v em Dom\u00ednio(X):\n      4. Se v \u00e9 consistente com atribui\u00e7\u00e3o:\n          5. Atribua X = v.\n          6. Result = BACKTRACKING(CSP, atribui\u00e7\u00e3o).\n          7. Se Result \u2260 falha:\n              Retorne Result.\n          8. Remova a atribui\u00e7\u00e3o X = v.\n  9. Retorne falha.\n</code></pre> C\u00f3digo 2: Implementa\u00e7\u00e3o em pseudo-c\u00f3digo do algoritmo Backtracking, Fonte: OPENAI. Assistente Virtual ChatGPT, 2024 <p>Podemos ver um exemplo para esclarecer melhor o a utiliza\u00e7\u00e3o do backtracking:</p> <p>Exemplo: Baseado no problema da mochila, pertencente ao \"Os 21 problemas NP-completos\", que foram introduzidos por Richard Karp em 1972, onde a ideia \u00e9 ter uma mochila com um limite de peso e quantidade de items, e temos uma quantidade Y de items. A utiliza\u00e7\u00e3o do algoritmo backtracking iria nos fornecer uma s\u00e9rie de combina\u00e7\u00f5es poss\u00edveis para alocarmos nossos itens na mochila. E se colocassemos uma restri\u00e7\u00e3o como a necessidade de levar obrigatoriamente uma lanterna e um tablet, o algoritmo iria analisar as combina\u00e7\u00f5es e iria evitar todas que n\u00e3o seguem essas condi\u00e7\u00f5es.</p>"},{"location":"portifolios/portifolio3/#busca-local","title":"Busca local","text":"<p>Esse algoritmo de busca local \u00e9 muito eficaz para resolver CSPs, ele utiliza a formula\u00e7\u00e3o de estados completos, onde o estado inicial atribui um valor a cada vari\u00e1vel, e no decorrer do processo de busca ele altera o valor de uma vari\u00e1vel por vez at\u00e9 chegar na solu\u00e7\u00e3o.</p> <p>A seguir no c\u00f3digo 3, podemos ver a implementa\u00e7\u00e3o em pseudo-c\u00f3digo do algoritmo:</p> <pre><code>BUSCA_LOCAL(CSP):\n  1. Inicialize uma atribui\u00e7\u00e3o completa (possivelmente aleat\u00f3ria).\n  2. Enquanto n\u00e3o atingir o limite de itera\u00e7\u00f5es:\n      3. Se a atribui\u00e7\u00e3o for uma solu\u00e7\u00e3o (todas as restri\u00e7\u00f5es satisfeitas):\n          Retorne atribui\u00e7\u00e3o.\n      4. Selecione uma vari\u00e1vel e altere seu valor para melhorar \n      o n\u00famero de restri\u00e7\u00f5es satisfeitas.\n  5. Retorne falha.\n\n</code></pre> C\u00f3digo 3: Implementa\u00e7\u00e3o em pseudo-c\u00f3digo do algoritmo de busca local, Fonte: OPENAI. Assistente Virtual ChatGPT, 2024 <p>Podemos ver um exemplo onde a utiliza\u00e7\u00e3o deste algoritmo seria idela para encontrar a solu\u00e7\u00e3o:</p> <p>Exemplo: Se pensarmos em uma problem\u00e1tica dentro de uma empresa, onde devemos distribuir da melhor forma poss\u00edvel tempo, dinheiro e materias, para benef\u00edcios totais, respeitando as condi\u00e7\u00f5es de limites de gastos e aloca\u00e7\u00e3o de tempos. O algoritmo de busca iria conseguir encontrar a melhor solu\u00e7\u00e3o para este problema.</p>"},{"location":"portifolios/portifolio3/#backtracking-recursivo","title":"Backtracking Recursivo","text":"<p>Baseado no algoritmo backtrancking, mas com uma leve altera\u00e7\u00e3o, durante o seu processo ele acumula um conjunto de conflitos, e ao mesmo tempo realiza a verifica a atribui\u00e7\u00e3o de valores v\u00e1lidos, e se n\u00e3o for encontrado nenhum valor v\u00e1lido, ele retorna o elemento mais recente do conjunto de conflito e o indicador de falha (RUSSEL; NORVIG, 2010).</p> <p>A seguir no c\u00f3digo 4, podemos ver a implementa\u00e7\u00e3o do algoritmo no pseudo-c\u00f3digo:</p> <pre><code>fun\u00e7\u00e3o retrocessoRecursivo(estado):\n    se \u00e9Solu\u00e7\u00e3o(estado):  // Verifica se o estado atual \u00e9 uma solu\u00e7\u00e3o\n        retornar estado  // Se for uma solu\u00e7\u00e3o, retorna o estado\n\n    para cada escolha em op\u00e7\u00f5esPoss\u00edveis(estado):  // Para cada escolha poss\u00edvel\n        novoEstado = aplicarEscolha(estado, escolha)  // Aplica a escolha e gera um novo estado\n\n        se \u00e9Vi\u00e1vel(novoEstado):  // Verifica se o novo estado \u00e9 vi\u00e1vel\n            resultado = retrocessoRecursivo(novoEstado)  // Chama recursivamente para o pr\u00f3ximo estado\n\n            se resultado != falha:  // Se encontrou uma solu\u00e7\u00e3o, retorna o resultado\n                retornar resultado\n\n    retornar falha  // Se nenhuma escolha levou a uma solu\u00e7\u00e3o, retorna falha\n</code></pre> C\u00f3digo 4: Implementa\u00e7\u00e3o em pseudo-c\u00f3digo do algoritmo de Backtracking Recursivo, Fonte: OPENAI. Assistente Virtual ChatGPT, 2024"},{"location":"portifolios/portifolio3/#estrutura-de-problemas","title":"Estrutura de Problemas","text":"<p>Ao se analisar os problemas de satisfa\u00e7\u00e3o de condi\u00e7\u00f5es, podemos ter diferentes vis\u00f5es para suas solu\u00e7\u00f5es, ao olhar as condi\u00e7\u00f5es de um problema, podemos simular eles em um grafo de condi\u00e7\u00f5es que pode ser utilizado para acelerar a busca por solu\u00e7\u00f5es. </p> <p>Baseado nos grafos de condi\u00e7\u00f5es, \u00e9 poss\u00edvel aplicarmos algums m\u00e9todos que facilitam a compreens\u00e3o e entendimento para a resolu\u00e7\u00e3o do problema, a seguir temos os seguintes m\u00e9todos:</p> <ul> <li>Decomposi\u00e7\u00e3o em subproblemas independentes: Se o grafo puder ser dividido em componentes desconectados, ent\u00e3o \u00e9 poss\u00edvel tratar o problema de forma separada;</li> <li>Grafos em \u00e1rvore: Se for poss\u00edvel tranformar o grafo em uma \u00e1rvore, fica mais f\u00e1cil de se aplicar uma abordagem eficiente para encontrar a solu\u00e7\u00e3o;</li> <li>Redu\u00e7\u00e3o de Grafos de Condi\u00e7\u00f5es a \u00c1rvores: No caso onde o grafo n\u00e3o \u00e9 uma \u00e1rvore, pode tentar eliminar vari\u00e1veis que fa\u00e7am o grafo restante se tornar uma \u00e1rvore;</li> <li>Decomposi\u00e7\u00e3o em \u00c1rvore de Grafos de Condi\u00e7\u00e3o: O grafo pode ser decomposto em problemas menores, e ao final, as solu\u00e7\u00f5es s\u00e3o combinadas.</li> </ul> <p>Ao se utilizar destes m\u00e9todos, se torna poss\u00edvel obter solu\u00e7\u00f5es de forma mais f\u00e1cil dentro de um problema.</p>"},{"location":"portifolios/portifolio3/#conclusao","title":"Conclus\u00e3o","text":"<p>Neste artigo, foi poss\u00edvel analisarmos um novo modelo de resolu\u00e7\u00e3o de problemas realizado pelos agentes. Esse modelo se baseia em uma s\u00e9rie de condi\u00e7\u00f5es que tornam um problema mais complexo para um agente inteligente, mas, entendo o problema de forma aprofundada, os tipos de condi\u00e7\u00f5es que ele possui, e outras caracter\u00edsticas que foram discutidas, \u00e9 poss\u00edvel chegarmos a uma solu\u00e7\u00e3o aplicando os algoritmos corretos.</p>"},{"location":"portifolios/portifolio3/#referencias","title":"Refer\u00eancias","text":"<p>[1] RUSSELL, Stuart; NORVIG, Peter. Intelig\u00eancia Artificial: Uma Abordagem Moderna \u2013 3\u00aa edi\u00e7\u00e3o. [2] OPENAI. Assistente Virtual ChatGPT. Respostas geradas com base em intelig\u00eancia artificial. Dispon\u00edvel em: https://openai.com. Acesso em: 24 dez. 2024. [3] WIKIPEDIA. AC-3 algorithm. Dispon\u00edvel em: https://en.wikipedia.org/wiki/AC-3_algorithm. Acesso em: 29 dez. 2024.</p>"},{"location":"portifolios/portifolio4/","title":"Portif\u00f3lio 4","text":""},{"location":"portifolios/portifolio4/#portifolio-4","title":"Portif\u00f3lio 4","text":""},{"location":"portifolios/portifolio4/#agentes-logicos","title":"Agentes L\u00f3gicos","text":"<p>\\vspace{10cm}</p> <p>Autor: Wildemberg Sales da Silva Junior</p> <p>Matr\u00edcula: 202017503</p> <p>Data: 04/01/2025</p> <p>Institui\u00e7\u00e3o/Universidade: Universidade de Bras\u00edlia(UnB)</p> <p>Disciplina: Intelig\u00eancia Artificial - FGA0221</p> <p>\\newpage</p>"},{"location":"portifolios/portifolio4/#resumo","title":"Resumo","text":"<p>Este artigo oferece uma vis\u00e3o abrangente sobre agentes baseados em conhecimento, explorando sua estrutura, funcionamento e os conceitos l\u00f3gicos que o agente possui. A artigo aborda a estrutura de um agente baseado em conhecimento, suas opera\u00e7\u00f5es TELL e ASK, al\u00e9m de demonstrar seu processo de resolu\u00e7\u00e3o de problema com um exemplo de c\u00f3digo. S\u00e3o explicadas as abordagens declarativa e procedural para constru\u00e7\u00e3o desses agentes, e o ambiente de teste \"Mundo de Wumpus\" \u00e9 apresentado para exemplificar os desafios de racioc\u00ednio e situa\u00e7\u00f5es de incerteza em que o agente pode estar. O artigo tamb\u00e9m introduz conceitos de l\u00f3gica, incluindo sintaxe, sem\u00e2ntica e consequ\u00eancia l\u00f3gica, e detalha a l\u00f3gica proposicional com seus operadores. Por fim, um exemplo pr\u00e1tico de um agente de diagn\u00f3stico m\u00e9dico, implementado em Python, demonstra o processo de infer\u00eancia e refor\u00e7a o potencial desses agentes em diversos setores.</p>"},{"location":"portifolios/portifolio4/#visao-geral","title":"Vis\u00e3o Geral","text":"<p>O tema abordado neste artigo foi de extrema import\u00e2ncia e valor, pois introduziu conceitos interessantes e valiosos sobre agentes inteligentes. Entender como um agente de IA pode aplicar l\u00f3gica em problemas, abre um leque de conhecimento cada vez maior. Suas aplica\u00e7\u00f5es e como ele se aproxima de uma l\u00f3gica humana, torna o assunto mais interessante, trazendo ideias e perpectivas novas para o conhecimento sobre IA.</p> <p>\\newpage</p>"},{"location":"portifolios/portifolio4/#introducao","title":"Introdu\u00e7\u00e3o","text":"<p>Neste artigo iremos abordar um novo modelo de agente inteligente, o agente baseado em conhecimento. Agentes baseados em conhecimento \u00e9 o caso definido por Russel e Norvig, 2010, \"em que projetamos agentes que podem formar representa\u00e7\u00f5es de um mundo complexo, usar um processo de infer\u00eancia para derivar novas representa\u00e7\u00f5es sobre o mundo e utilizar essas novas representa\u00e7\u00f5es para deduzir o que fazer\".</p> <p>Esses agentes s\u00e3o baseados em uma abordagem de pensamento humano, pois humanos utilizam representa\u00e7\u00f5es internas de conhecimento para resolver problemas e tomar decis\u00f5es, e quando aplicada \u00e0 intelig\u00eancia artificial(IA), temos a gera\u00e7\u00e3o de um agente baseado em conhecimento.</p> <p>No decorrer deste artigo iremos obter uma vis\u00e3o geral sobre a funcionalidade desses agentes, suas defini\u00e7\u00f5es, os conceitos que formam a l\u00f3gica e conhecimento, e os processos de infer\u00eancia realizados por esses agentes.</p>"},{"location":"portifolios/portifolio4/#agente-baseado-em-conhecimento","title":"Agente baseado em conhecimento","text":"<p>Como dito anteriormente, agentes baseados em conhecimentos tendem a possuir uma abordagem aproximada do pensamento humano, onde a partir do seu conhecimento, ele toma uma s\u00e9rie de decis\u00f5es.</p> <p>Esses agentes tem como seu principal componente a base de conhecimento(KB), essa base de conhecimento \u00e9 composta por uma s\u00e9rie de senten\u00e7as que s\u00e3o expressas em uma linguagem de representa\u00e7\u00e3o de conhecimento, onde essa linguagem representa alguma afirma\u00e7\u00e3o sobre o mundo. As senten\u00e7as tamb\u00e9m podem ser chamadas de axiomas quando s\u00e3o tomadas como verdade sem serem derivadas de outras (RUSSEL; NORVIG, 2010).</p> <p>Nas bases de conhecimento deve haver modos de criar novas seten\u00e7as e consut\u00e1-las, essas opera\u00e7\u00f5es s\u00e3o nomeadas como TELL(informe) e ASK(pergunte), essas opera\u00e7\u00f5es podem envolver processos de infer\u00eancia que \u00e9 a deriva\u00e7\u00e3o de novas seten\u00e7as a partir de antigas. Quando o processo de infer\u00eancia \u00e9 aplicado, se deve sequir algums crit\u00e9rios, que \u00e9 quando se faz uma pergunta a base de conhecimento, ela deve ser respondida com o que est\u00e1 na base de conhecimento.</p> <p>A seguir no c\u00f3digo 1 podemos observar a implementa\u00e7\u00e3o abstrata em um esbo\u00e7o de um agente baseado em conhecimento.</p> <pre><code> fun\u00e7\u00e3o AGENTE-KB(percep\u00e7\u00e3o) retorna uma a\u00e7\u00e3o\n    persistente: KB, uma base de conhecimento\n                t, um contador, inicialmente igual a 0, indicando tempo\n    TELL(KB, CRIAR-SENTEN\u00c7A-DE-PERCEP\u00c7\u00c3O(percep\u00e7\u00e3o, t))\n    a\u00e7\u00e3o \u2190 ASK(KB CRIAR-CONSULTA-DE-A\u00c7\u00c3O(t))\n    TELL(KB, CRIAR-SENTEN\u00c7A-DE-A\u00c7\u00c3O(a\u00e7\u00e3o, t))\n    t \u2190 t + 1\n    retornar a\u00e7\u00e3o\n ````\n&lt;figcaption align=\"center\"&gt;&lt;b&gt;C\u00f3digo 1&lt;/b&gt;: Implementa\u00e7\u00e3o de um agente baseado em conhecimento, Fonte: RUSSELL, Stuart; NORVIG, Peter. Intelig\u00eancia Artificial: Uma Abordagem Moderna, 2010, p. 285, figura 7.1&lt;/figcaption&gt;\n\nUm agente baseado em conhecimento opera seguindo 3 etapas principais, onde a primeira \u00e9 a de percep\u00e7\u00e3o, que \u00e9 o momento em que ele percebe o ambiente em que est\u00e1 inserido e atualiza sua base de conhecimento, a segunda \u00e9 a consulta, onde ele consulta sua base de conhecimento para decidir sua pr\u00f3xima a\u00e7\u00e3o no ambiente, e a terceira \u00e9 a de execu\u00e7\u00e3o, onde ele informa a base de conhecimento sua a\u00e7\u00e3o e a executa. Esses agentes independem de suas implementa\u00e7\u00f5es espec\u00edficas, eles focam no que sabem e nas suas metas, um exemplo que pode ser citado \u00e9 de um \u00f4nibus automorizado, que sabe como navegar em uma cidade, com base nos conhecimentos que possui e nos conhecimentos retirados do ambiente.\n\nOs agentes podem ser criados seguindo dois tipos de abordagem:\n\n* **Abordagem declarativa:** Onde s\u00f3 s\u00e3o passadas informa\u00e7\u00f5es para sua base de conhecimento e ele ir\u00e1 definir como agir baseado nessas informa\u00e7\u00f5es, seguindo as regras que foram informadas;\n* **Abordagem Procedural:** Neste modelo \u00e9 passado para o usu\u00e1rio as regras e intru\u00e7\u00f5es de como agir em um ambiente, sem necessariamente informar a ele uma base de conhecimento;\n\n## O mundo de Wumpus\nO mundo de Wumpus \u00e9 um ambiente de teste utilizado para media as capacidades de racioc\u00ednio e conhecimento de agentes KB. Esse modelo de forma mais geral, \u00e9 uma grade 4x4 que representa uma caverna guardada pelo monstro Wumpus, essa caverna possui alguns po\u00e7os espalhados por ela que se o agente cair em um deles, ele perde, no in\u00edcio o agente come\u00e7a no canto inferior esquerdo, e tem o objetivo de coletar o m\u00e1ximo de ouro espalhado pela caverna e depois sair dela pelo mesmo lugar que entrou, enquanto evita os po\u00e7os e o monstro Wumpus. O agente tamb\u00e9m pode matar o monstro Wumpus, basta ele usar uma flecha, mas isso d\u00e1 um desconto de pontua\u00e7\u00e3o do agente. A seguir vamos entender com mais detalhes esse mapa, e tamb\u00e9m podemos ver um exemplo do mapa na *figura 1*:\n\n![alt text](image.png)\n&lt;figcaption&gt;&lt;b&gt;C\u00f3digo 1&lt;/b&gt;: Teste do mundo de Wumpus, Fonte: RUSSELL, Stuart; NORVIG, Peter. Intelig\u00eancia Artificial: Uma Abordagem Moderna, 2010, p. 288, figura 7.2&lt;/figcaption&gt;\n\n* Descri\u00e7\u00e3o do Ambiente:\n    * Uma caverna de 16 blocos (4x4), onde cada bloco pode conter ouro, po\u00e7os ou o Wumpus;\n    * A entrada e sa\u00edda da caverna onde o agente come\u00e7a fica no canto inferior esquerdo;\n\n* Funcionamento do Ambiente:\n    * O agente pode movimentar para a esquerda ou para a direita no \u00e2ngulo de 90\u00b0;\n    * O agente pode disparar flecha em linha reta somente, e s\u00f3 pode ser usada uma vez;\n    * O agente pode sair da caverna mas apenas voltando para o bloco inicial;\n    * O agente conta com alguns sensores:\n        * Fedor: Onde ele percebe que o monstro esta nas salas adjacentes;\n        * Brisa: Significa que existe um po\u00e7o em uma sala adjacente;\n        * Brilho: Siginifica que existe ouro na sala;\n        * Impacto: Siginifica que ele chegou a um limite de deslocamento naquela dire\u00e7\u00e3o (parede);\n        * Grito: Significa que a flecha que o agente disparou matou o wumpus;\n\n* Desafios do Ambiente:\n    * O agente n\u00e3o consegue observar todo o ambiente em que est\u00e1 inserido, ele s\u00f3 enxerga localmante e usa infer\u00eancias para as a\u00e7\u00f5es;\n    * As a\u00e7\u00f5es do agente provocam as recompensas ou as penalidades, deste modo ele deve ficar lidando com a incerteza;\n    * Sua ignor\u00e2ncia inicial sobre o ambiente, onde o agente n\u00e3o sabe o que fazer no in\u00edcio da caverna;\n\n* Regras das pontua\u00e7\u00f5es:\n    * +1000 se sair da caverna com o outro;\n    * -1000 se morrer na caverna, seja pelos po\u00e7os ou pelo monstro;\n    * -10 se disparar a flecha;\n    * -1 por cada a\u00e7\u00e3o realizada;\n\nPortanto, o agente deve trabalhar baseado nessas regras para cumprir seu objetivo e alcan\u00e7ar as suas metas, que no caso, o agente deve sair com o m\u00e1ximo de ouro da caverna.\n\n## L\u00f3gica\nAt\u00e9 o presente momento, exploramos o modelo de agente baseado em conhecimento de forma mais superficial, a partir de agora, iremos explorar algumas nuances desse modelo. Neste t\u00f3pico iremos discutir sobre o que \u00e9 l\u00f3gica, seus conceitos e defini\u00e7\u00f5es, e como isso se aplica a um agente.\n\nDurante o per\u00edodo de 384 a.C. e 322 a.C., o fil\u00f3sofo grego Arist\u00f3teles criou o estudo da l\u00f3gica, essa l\u00f3gica em seu contexto seria uma s\u00e9rie de restri\u00e7\u00f5es em que o conhecimento deveria passar para ser reconhecido como um conhecimento verdadeiro e universal. Se pensarmos na l\u00f3gica que Arist\u00f3teles descreveu e trouxermos isso para o nosso contexto de agentes, vamos descobrir que os agentes baseados em conhecimentos se utilizam da l\u00f3gica proposicional para realizar suas infer\u00eancias a partir das senten\u00e7as contidas em sua base.\n\nAs sente\u00e7as que fazem parte da base de conhecimento de um agente seguem uma sintaxe que imp\u00f5e regras de forma\u00e7\u00e3o para dar sentido a elas. Se pegarmos um exemplo de um c\u00e1lculo simplem como \"X+Y=4\", essa f\u00f3rmula faz sentido pois ela segue um padr\u00e3o v\u00e1lido, mas se pergarmos um modelo como \"X4Y = +\", a f\u00f3rmula j\u00e1 perde o sentido e se torna uma senten\u00e7a inv\u00e1lida. Por isso \u00e9 importante seguir a sintaxe ao fornecer conhecimento a um agente.\n\nAs senten\u00e7as tamb\u00e9m devem possuir sem\u00e2ntica, que \u00e9 o significa das senten\u00e7as em rela\u00e7\u00e3o aos mundos poss\u00edveis, ou seja, os valores verdadeiros e falsos que cada senten\u00e7a deve ter quando exposta a valores diferentes. Um exemplo \u00e9 a f\u00f3rmula \"X+Y=4\" ela \u00e9 verdadeira quando X e Y s\u00e3o iguais a 2, mas \u00e9 falsa quando X e Y s\u00e3o iguais a 1. Um fator importante \u00e9 que as senten\u00e7as nunca ser\u00e3o \ndiferentes de verdadeiro ou falso, pois n\u00e3o existe um valor intermedi\u00e1rio que elas possam assumir.\n\nOutro termo importante para ser discutido dentro de l\u00f3gica \u00e9 a **consequ\u00eancia l\u00f3gica**, que nada mais \u00e9 do que a afirma\u00e7\u00e3o de que se em um conjunto de A e B, se A for sempre verdadeiro, ent\u00e3o B tamb\u00e9m ser\u00e1 verdadeiro, logo, B \u00e9 uma consequ\u00eancia de A. Com isso podemos afirmar que o conjunto de A est\u00e1 contido no conjunto de B, portanto, A \u00e9 consequ\u00eancia de B, se e somente se A est\u00e1 contido em B.\n\nSe observamos a fundo como os agentes KB trabalham em suas infer\u00eancias, iremos perceber que eles se utilizam da **l\u00f3gica proposicional** que \u00e9 uma forma de representa\u00e7\u00e3o do racioc\u00ednio l\u00f3gico, essa l\u00f3gica trabalha diretamente com as senten\u00e7as contidas na KB dos agentes e possui uma s\u00e9rie de operadores l\u00f3gicos, dentre eles est\u00e3o: \n\n* Nega\u00e7\u00e3o (NOT): Faz a invers\u00e3o do valor de uma senten\u00e7a, ou seja, se a senten\u00e7a for verdadeira, ela se torna falsa, e se for falsa, ela se torna verdadeira;\n* Conjun\u00e7\u00e3o (AND): Une duas senten\u00e7as e as avalia, se as duas forem verdadeiras, ent\u00e3o o valor delas vai ser verdadeiro, se uma delas for falsa, o valor ser\u00e1 falso; \n* Disjun\u00e7\u00e3o (OR): Na uni\u00e3o das duas senten\u00e7as, basta somente uma ser verdadeira para que o valor resultante seja verdadeiro, caso contr\u00e1rio, ser\u00e1 falso;\n* Condicional: Uma senten\u00e7a s\u00f3 ser\u00e1 verdadeira, se a outra da uni\u00e3o for verdadeira; \n* Bicondicional: O valor resultante s\u00f3 \u00e9 verdadeiro quando as duas senten\u00e7as tem o mesmo valor;\n\nAgora para senten\u00e7as complexas, existe uma varia\u00e7\u00e3o desses operadores, se pegarmos duas senten\u00e7as X e Y, temos:\n\n* NOT X \u00e9 verdadeiro se e somente se X \u00e9 falso;\n* X AND Y \u00e9 verdadeiro se e somente se X e Y forem verdadeiros;\n* X OR Y \u00e9 verdadeiro se e somente se X ou Y forem verdadeiros;\n* X CONDI\u00c7\u00c3O(Y) \u00e9 verdadeiro a menos que X seja verdadeiro e Q seja falso;\n* X BICONDICIONAL Y \u00e9 verdadeiro sse X e Y s\u00e3o ambos verdadeiros ou ambos falsos;\n\nA seguir podemos ver na *tabela 1* o resumo das poss\u00edveis condi\u00e7\u00f5es:\n\n| X     | Y     | NOT X | X AND Y | X OR Y | X CONDI\u00c7\u00c3O Y | X BICONDICIONAL Y |\n|-------|-------|-------|---------|--------|--------------|--------------------|\n| True  | True  | False | True    | True   | True         | True               |\n| True  | False | False | False   | True   | False        | False              |\n| False | True  | True  | False   | True   | True         | False              |\n| False | False | True  | False   | False  | True         | True               |\n&lt;figcaption&gt;&lt;b&gt;Tabela 1&lt;/b&gt;: Poss\u00edveis condi\u00e7\u00f5es para as opera\u00e7\u00f5es l\u00f3gicas em senten\u00e7as complexas&lt;/figcaption&gt;\n\n## Processo de infer\u00eancia\nPara entermos o processo de infer\u00eancia realizado por um agente, podemos analisar o seguinte exemplo:\n\nUm agente aplicado na \u00e1rea m\u00e9dica, deve auxiliar os m\u00e9dicos no diagn\u00f3stico de doen\u00e7as utilizando um conjunto de regras baseadas em sintomas, neste modelo de agentes iremos trabalhar na abordagem declarativa:\n\n* Estado do paciente:\n    * Est\u00e1 com febre;\n    * Est\u00e1 com tosse seca;\n    * Est\u00e1 com dificuldade em respirar;\n\n* Regras (Senten\u00e7as):\n    * Se o paciente est\u00e1 com febre e tem tosse seca, ent\u00e3o o paciente pode ter uma infec\u00e7\u00e3o viral;\n    * Se o paciente tem dificuldade para respirar e febre, ent\u00e3o o paciente pode ter pneumonia;\n    * Se o paciente pode ter uma infec\u00e7\u00e3o viral e dificuldade para respirar, ent\u00e3o o paciente deve ser avaliado para COVID.\n\n* Processo de infer\u00eancia:\n    * O agente recebe os dados do paciente, e analisa os sintomas;\n    * O agente verifica as regras e aplica aos sintomas;\n    * Todas as senten\u00e7as d\u00e3o resultado verdadeiro;\n    * Ele constata que o paciente est\u00e1 com pneumonia, infec\u00e7\u00e3o viral, e deve ser avaliado para a COVID;\n\nSe aplicarmos o exemplo a um c\u00f3digo em python, iremos ter a aplica\u00e7\u00e3o de um agente baseado em l\u00f3gica proposicional. No *c\u00f3digo 2* \u00e9 poss\u00edvel ver a aplica\u00e7\u00e3o desse agente em python:\n\n````python\nclass AgenteBaseadoEmConhecimento:\n    def __init__(self):\n        # Fatos conhecidos sobre o paciente\n        self.febre = False\n        self.tosse_seca = False\n        self.dificuldade_respirar = False\n\n        # Diagn\u00f3sticos poss\u00edveis\n        self.infeccao_viral = False\n        self.pneumonia = False\n        self.avaliacao_covid = False\n\n    def receber_fatos(self, febre, tosse_seca, dificuldade_respirar):\n        # Atribuindo os fatos conhecidos\n        self.febre = febre\n        self.tosse_seca = tosse_seca\n        self.dificuldade_respirar = dificuldade_respirar\n\n    def aplicar_regras(self):\n        # Aplicando as regras de infer\u00eancia\n\n        # Regra 1: Se o paciente est\u00e1 com febre e tem tosse seca, pode ter uma infec\u00e7\u00e3o viral\n        if self.febre and self.tosse_seca:\n            self.infeccao_viral = True\n\n        # Regra 2: Se o paciente tem dificuldade para respirar e febre, pode ter pneumonia\n        if self.febre and self.dificuldade_respirar:\n            self.pneumonia = True\n\n        # Regra 3: Se o paciente tem infec\u00e7\u00e3o viral e dificuldade para respirar, deve ser avaliado para COVID-19\n        if self.infeccao_viral and self.dificuldade_respirar:\n            self.avaliacao_covid = True\n\n    def diagnostico(self):\n        # Exibindo o diagn\u00f3stico com base nas conclus\u00f5es\n        if self.infeccao_viral:\n            print(\"Diagn\u00f3stico: O paciente pode ter uma infec\u00e7\u00e3o viral.\")\n        if self.pneumonia:\n            print(\"Diagn\u00f3stico: O paciente pode ter pneumonia.\")\n        if self.avaliacao_covid:\n            print(\"Diagn\u00f3stico: O paciente deve ser avaliado para COVID-19.\")\n        if not (self.infeccao_viral or self.pneumonia or self.avaliacao_covid):\n            print(\"Diagn\u00f3stico: N\u00e3o foi poss\u00edvel determinar um diagn\u00f3stico com base nos dados fornecidos.\")\n\n# Criando o agente\nagente = AgenteBaseadoEmConhecimento()\n\n# Definindo os fatos para o paciente (febre, tosse seca, dificuldade para respirar)\nagente.receber_fatos(febre=True, tosse_seca=True, dificuldade_respirar=True)\n\n# Aplicando as regras para obter o diagn\u00f3stico\nagente.aplicar_regras()\n\n# Exibindo o diagn\u00f3stico final\nagente.diagnostico()\n</code></pre> C\u00f3digo 2: Implementa\u00e7\u00e3o em python do exemplo do agente de diagn\u00f3stico de doen\u00e7as, Fonte: OPENAI. Assistente Virtual ChatGPT, 2024"},{"location":"portifolios/portifolio4/#conclusao","title":"Conclus\u00e3o","text":"<p>Portanto, baseado em tudo que foi estudado e explorado neste artigo, foi poss\u00edvel obter uma vis\u00e3o abrangente sobre o funcionamento de agentes baseados em conhecimento e como eles funcionam, al\u00e9m de explorarmos exemplos de atua\u00e7\u00f5es desse agente, tamb\u00e9m conseguimos explorar o que \u00e9 l\u00f3gica, e o modelo de l\u00f3gica que esses agentes utilizam.  Portanto, podemos concluir que agentes baseados em conhecimento s\u00e3o muito flex\u00edveis e podem atuar em diversos ambientes utilizando a l\u00f3gica e a infer\u00eancia para se chegar \u00e0 suas metas. Diversas setores podem utilizar estes tipos de agentes para otimizar os processos, podemos afirmar isso baseado nos exemplos mostrados, como o \u00f4nibus automotorizado e o agente de diagn\u00f3stico m\u00e9dico.</p>"},{"location":"portifolios/portifolio4/#referencias","title":"Refer\u00eancias","text":"<p>[1] RUSSELL, Stuart; NORVIG, Peter. Intelig\u00eancia Artificial: Uma Abordagem Moderna \u2013 3\u00aa edi\u00e7\u00e3o. [2] OPENAI. Assistente Virtual ChatGPT. Respostas geradas com base em intelig\u00eancia artificial. Dispon\u00edvel em: https://openai.com. Acesso em: 04 dez. 2024.  </p>"},{"location":"portifolios/portifolio6/","title":"Portif\u00f3lio 6","text":""},{"location":"portifolios/portifolio6/#portifolio-6","title":"Portif\u00f3lio 6","text":""},{"location":"portifolios/portifolio6/#aprendizado-de-maquina","title":"Aprendizado de M\u00e1quina","text":"<p>\\vspace{10cm}</p> <p>Autor: Wildemberg Sales da Silva Junior</p> <p>Matr\u00edcula: 202017503</p> <p>Data: 15/02/2025</p> <p>Institui\u00e7\u00e3o/Universidade: Universidade de Bras\u00edlia(UnB)</p> <p>Disciplina: Intelig\u00eancia Artificial - FGA0221</p> <p>\\newpage</p>"},{"location":"portifolios/portifolio6/#resumo","title":"Resumo","text":"<p>Neste artigo foram abordados conceitos fundamentais sobre o aprendizado de m\u00e1quina, desde a base e do porque da aprendizado de agentes, at\u00e9 sua utiliza\u00e7\u00e3o em problemas reais. Foram abordados de forma simples e direta conceitos complexos para uma facilita\u00e7\u00e3o do aprendizado sobre alguns dos temas, e em outros casos, assuntos foram aprofundados para que fosse poss\u00edvel obter um entendimento melhor de assuntos mais complexos. Por fim abordamos alguns dos principais algoritmos de forma detalhada, explicando seu funcionamento e aplicando em c\u00f3digo a exemplos.</p>"},{"location":"portifolios/portifolio6/#visao-geral","title":"Vis\u00e3o Geral","text":"<p>O conte\u00fado de aprendizado de m\u00e1quina \u00e9 rico e muito interessante, os cen\u00e1rios em que costumam ser aplicados, e as oportunidades de aplica\u00e7\u00f5es que eles proporcionam para a solu\u00e7\u00e3o de problemas complexos, enriquecem ainda mais os conte\u00fados relacionados a IA. Estudar esse conte\u00fado traz uma vis\u00e3o muito mais pr\u00e1tica e funcional do que muito outros campos dentro de intelig\u00eancia artificial, com esse aspecto, o conte\u00fado engaja ainda mais o leitor no estudo sobre IA.</p> <p>\\newpage</p>"},{"location":"portifolios/portifolio6/#introducao","title":"Introdu\u00e7\u00e3o","text":"<p>Neste artigo iremos discutir sobre o sistema de aprendizado dos agentes inteligentes, seus diferentes algoritmos, e suas caracter\u00edsticas aplicadas \u00e0 problemas reais do nosso cotidiano, com o foco de nos aprofundarmos cada vez mais no que \u00e9 o aprendizado de m\u00e1quina.  Primeiramente devemos entender porqu\u00ea um agente precisa aprender, e para explicar melhor podemos definir tr\u00eas pilares principais que explicam o motivo do aprendizado, esses pilares s\u00e3o a adapta\u00e7\u00e3o a novos cen\u00e1rios, a adapta\u00e7\u00e3o a mudan\u00e7as ao longo do tempo, e por \u00faltimo, a resolu\u00e7\u00e3o de tarefas complexas (RUSSEL; NORVIG, 2010). Nos t\u00f3picos a seguir iremos nos aprofundar nesses pilares fazendo um estudo aprofundado sobre as caracter\u00edsticas dos agentes que aprendem e dos diferentes tipos de aprendizado que eles utilizam, para que ao final possamos ter uma vis\u00e3o completa do que \u00e9 o aprendizado de m\u00e1quina.</p>"},{"location":"portifolios/portifolio6/#aprendizado-de-maquina_1","title":"Aprendizado de M\u00e1quina","text":"<p>Como dito anteriormente, um agente inteligente aprende por causa de tr\u00eas pilares bases: a adapta\u00e7\u00e3o a novos cen\u00e1rios, a adapta\u00e7\u00e3o a mudan\u00e7as ao longo do tempo, e por \u00faltimo, a resolu\u00e7\u00e3o de tarefas complexas (RUSSEL; NORVIG, 2010).  Um agente deve estar apto a trabalhar em novos cen\u00e1rios pois os projetistas n\u00e3o podem prever todas as situa\u00e7\u00f5es poss\u00edveis em um problema complexo, por isso \u00e9 interessante que uma agente aprenda a lidar com as mudan\u00e7as, e a diferentes resultados ou problemas. Tamb\u00e9m \u00e9 necess\u00e1rio que um agente consiga se adaptar a mudan\u00e7as ao longo do tempo e n\u00e3o se tornar obsoleto no decorrer do tempo, ele deve consigar aprender um conte\u00fado espec\u00edfico e realizar previs\u00f5es para o futuro, como por exemplo prever o pre\u00e7o de a\u00e7\u00f5es na bolsa de valores. E por \u00faltimo, o agente deve ser capaz de resolver tarefas complexas baseado no seu aprendizado, pois muitas tarefas n\u00e3o s\u00e3o triviais de serem programadas por humanos, algumas requerem meses ou anos para serem realizadas, e com isso, se uma agente aprende a resolver problemas complexos, eles ir\u00e3o transformar tarefas que levam meses para serem conclu\u00eddas, em tarefas que podem ser resolvidas em dias ou horas at\u00e9.  Portanto, o aprendizado de um agente vai muito al\u00e9m dele entender o seu problema, e sim conseguir adaptar solu\u00e7\u00f5es a novos problemas, prever pos\u00edveis novos problemas ou novas solu\u00e7\u00f5es baseado no que j\u00e1 realizou, e otimizar o processo de realiza\u00e7\u00e3o de tarefas complexas. Ent\u00e3o, um agente que consegue utilizar ao menos um dos pilares discutidos, ir\u00e1 conseguir solucionar milhares de problemas de forma otimizada. Uma quest\u00e3o que fica \u00e9: Como um agente pode aprender? E qual o tipo de aprendizado ele precisa ter para resolver um problema espec\u00edfico? No t\u00f3pico a seguir iremos explorar mais sobre os tipos de aprendizado que uma agente pode ter, e quais caracteristicas e utilidades que um agente pode obter baseado no seu aprendizado.</p>"},{"location":"portifolios/portifolio6/#tipos-de-aprendizados","title":"Tipos de Aprendizados","text":"<p>Os tipos de aprendizado que um agente pode realizar est\u00e1 relacionado em sua entradas e sa\u00edda de dados, com isso devemos compreender as tr\u00eas formas de entradas de dados que s\u00e3o supervisionada, n\u00e3o supervisionada e refor\u00e7o, e as duas formas de sa\u00edda retornada pelo agente, que s\u00e3o classifica\u00e7\u00e3o e regress\u00e3o.     </p>"},{"location":"portifolios/portifolio6/#supervisionado","title":"Supervisionado","text":"<p>O aprendizado supervisionado se d\u00e1 quando o agente, recebe um conjunto de valores que possui pares de entrada-sa\u00edda e com isso cria uma fun\u00e7\u00e3o que atende a l\u00f3gica de processar a entrada e retornar a sa\u00edda. Podemos explicar melhor com um exemplo, imagine que nosso agente tem a responsabilidade de calcular valores de casas baseados em diferentes par\u00e2metros (N\u00e3o s\u00e3o importantes no momento quais par\u00e2metros), com isso n\u00f3s fornecemos a esse agente uma s\u00e9rie de dados de casas que sabemos suas caracter\u00edsticas e seus valores, com esses dados o agente vai entender os padr\u00f5es de caracter\u00edsticas (entrada) que fazem a casa ter o valor dela (sa\u00edda), com isso quando precisarmos que o agente estipule um valor de uma nova casa na regi\u00e3o, basta fornecer as caracter\u00edsticas dela \u00e0 ele, que ele ir\u00e1 retornar o valor estipulado para a casa, tudo isso porqu\u00ea ele criou uma fun\u00e7\u00e3o que consegue realizar esse tipo de c\u00e1lculo. A seguir no c\u00f3digo 1 podemos ver o exemplo de aplica\u00e7\u00e3o em c\u00f3digo, e a sa\u00edda dos testes na Imagem 1.</p> <pre><code>import tensorflow as tf\nimport numpy as np\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nimport matplotlib.pyplot as plt\nfrom keras.utils import plot_model\n\ndata = tf.keras.datasets.boston_housing\n(x_train, y_train), (x_test, y_test) = data.load_data()\nmedia = x_train.mean(axis = 0)\ndesvio = x_train.std(axis = 0)\nx_train = (x_train - media) / desvio\nx_test = (x_test - media) / desvio\n\nmodel = Sequential([\n    Dense(units = 64, \n        activation = 'relu', \n        input_shape = [13]), \n    Dense(units = 64, \n        activation = 'relu'),\n    Dense(units = 1) \n])\n\nmodel.compile(optimizer = 'adam', \n    loss = 'mse',\n    metrics = ['mae'])\n\nhistory = model.fit(\n    x_train,\n    y_train,\n    epochs = 100, \n    validation_split = 0.2\n)\n\nx_new = x_test\ny_pred = model.predict(x_new)\n# Converter as previs\u00f5es do modelo para uma lista\ny_pred_list = [pred[0] for pred in y_pred]\n\n# Calcular a m\u00e9dia dos valores reais\ny_test_mean = np.mean(y_test)\n\n# Plotar os valores reais, as previs\u00f5es do modelo e a linha da m\u00e9dia\nplt.plot(y_test, label='Valores Reais')\nplt.plot(y_pred_list, label='Previs\u00f5es do Modelo', linestyle='--')\nplt.axhline(y_test_mean, color='r', linestyle='-', label='M\u00e9dia dos Valores Reais')\nplt.xlabel('Amostras')\nplt.ylabel('Pre\u00e7o das Casas')\nplt.title('Compara\u00e7\u00e3o entre Valores Reais e Previs\u00f5es do Modelo')\nplt.legend()\nplt.show()\n</code></pre> C\u00f3digo 1: Implementa\u00e7\u00e3o em c\u00f3digo do exemplo de predi\u00e7\u00e3o de valores de casas. Fonte: Autor <p></p> <p></p> Imagem 1: Comparativo dos resultados do exemplo de predi\u00e7\u00e3o de valores de casas. Fonte: Autor"},{"location":"portifolios/portifolio6/#nao-supervisionado","title":"N\u00e3o Supervisionado","text":"<p>O aprendizado n\u00e3o supervisionado acontece quando no conjunto de dados fornecidos ao agente, n\u00e3o existe um par de valores entrada-sa\u00edda, somente valores de entrada, com isso, o algoritmo fica respons\u00e1vel por fazer a classifica\u00e7\u00e3o dos dados de forma independente. Um exemplo que pode ser utilizado \u00e9 um agente aplicado em lojas que analisa os compradores e verifica os diferentes comportamentos de consumo deles. No c\u00f3digo 2 temos a aplica\u00e7\u00e3o do exemplo.</p> <pre><code>import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import StandardScaler\n\n# Criando um conjunto de dados fict\u00edcio (Renda Anual vs. Pontua\u00e7\u00e3o de Gastos)\nnp.random.seed(42)\nclientes = pd.DataFrame({\n    'Renda Anual (mil)': np.random.randint(20, 120, 100),  # Entre 20k e 120k\n    'Pontua\u00e7\u00e3o de Gastos': np.random.randint(1, 100, 100)   # Escala de 1 a 100\n})\n\n# Normalizando os dados para melhor performance do K-Means\nscaler = StandardScaler()\ndados_normalizados = scaler.fit_transform(clientes)\n\n# Aplicando o algoritmo K-Means\nkmeans = KMeans(n_clusters=4, random_state=42, n_init=10)\nclientes['Cluster'] = kmeans.fit_predict(dados_normalizados)\n\n# Visualizando os clusters\nplt.figure(figsize=(8, 6))\nplt.scatter(clientes['Renda Anual (mil)'], clientes['Pontua\u00e7\u00e3o de Gastos'], \n            c=clientes['Cluster'], cmap='viridis', edgecolors='black', s=80)\nplt.scatter(kmeans.cluster_centers_[:, 0] * scaler.scale_[0] + scaler.mean_[0], \n            kmeans.cluster_centers_[:, 1] * scaler.scale_[1] + scaler.mean_[1], \n            c='red', marker='X', s=200, label='Centroides')\n\nplt.xlabel('Renda Anual (mil)')\nplt.ylabel('Pontua\u00e7\u00e3o de Gastos')\nplt.title('Segmenta\u00e7\u00e3o de Clientes com K-Means')\nplt.legend()\nplt.show()\n\n# Exibir os primeiros registros com os clusters atribu\u00eddos\nprint(clientes.head())\n\n</code></pre> C\u00f3digo 2: Implementa\u00e7\u00e3o em c\u00f3digo do exemplo de classifica\u00e7\u00e3o de compradores. Fonte: OPENAI. Assistente Virtual ChatGPT, 2025 <p></p> <p></p> Imagem 2: Exemplo de sa\u00edda do algoritmo de an\u00e1lise de compradores. Fonte: Autor"},{"location":"portifolios/portifolio6/#reforco","title":"Refor\u00e7o","text":"<p>O aprendizado por refor\u00e7o \u00e9 diferentes dos outros aprendizados j\u00e1 citados, neste modelo o agente aprende baseado em tentativas e erros interagindo com o ambiente em que est\u00e1 cituado, com isso, ele executa uma s\u00e9rie de a\u00e7\u00f5es em busca de recompensa, mas caso ele fa\u00e7a algo \"errado\", ele recebe uma puni\u00e7\u00e3o que corrige seus pr\u00f3ximos passos. Um exemplo de agente que aprende com esse modelo \u00e9 um agente que trabalha com compra, venda e mantimento de a\u00e7\u00f5es no mercado financeiro, onde sua recompensa \u00e9 ter lucro, e sua puni\u00e7\u00e3o \u00e9 ter preju\u00edzo. No c\u00f3digo 3 podemos ter um exemplo com dados simulados para entendermos a din\u00e2mica do agente, e na imagem 3 o resultado da evolu\u00e7\u00e3o do saldo que o agente coordenava.</p> <pre><code>import numpy as np\nimport random\nimport matplotlib.pyplot as plt\n\n# Simula\u00e7\u00e3o de pre\u00e7os de a\u00e7\u00f5es (100 dias)\nnp.random.seed(42)\nprecos = np.cumsum(np.random.randn(100) * 2 + 100)  # Criando pre\u00e7os fict\u00edcios\n\n# Par\u00e2metros do Q-Learning\nacoes = [0, 1, 2]  # 0: Manter, 1: Comprar, 2: Vender\nq_table = np.zeros((100, len(acoes)))  # Tabela Q inicializada com zeros\ngamma = 0.95  # Fator de desconto\nalpha = 0.1   # Taxa de aprendizado\nepsilon = 1.0  # Explora\u00e7\u00e3o inicial\nepsilon_decay = 0.995  # Decaimento da explora\u00e7\u00e3o\nepisodios = 500  # N\u00famero de epis\u00f3dios\n\n# Treinamento do agente\nfor episodio in range(episodios):\n    saldo = 1000  # Saldo inicial\n    acao_atual = None\n    for dia in range(len(precos) - 1):\n        estado = dia\n        if random.uniform(0, 1) &lt; epsilon:\n            acao = random.choice(acoes)  # Explora\u00e7\u00e3o\n        else:\n            acao = np.argmax(q_table[estado])  # Explora\u00e7\u00e3o baseada na Tabela Q\n\n        # Defini\u00e7\u00e3o da recompensa\n        recompensa = 0\n        if acao == 1 and saldo &gt;= precos[dia]:  # Comprar\n            acao_atual = precos[dia]\n            saldo -= precos[dia]\n        elif acao == 2 and acao_atual is not None:  # Vender\n            recompensa = precos[dia] - acao_atual  # Lucro ou preju\u00edzo\n            saldo += precos[dia]\n            acao_atual = None\n\n        proximo_estado = min(dia + 1, len(precos) - 1)\n        q_table[estado, acao] = (1 - alpha) * q_table[estado, acao] + \\\n            alpha * (recompensa + gamma * np.max(q_table[proximo_estado]))\n\n    epsilon *= epsilon_decay  # Redu\u00e7\u00e3o da explora\u00e7\u00e3o\n\n# Teste do agente treinado\nsaldo = 1000\nacao_atual = None\nlucros = []\nfor dia in range(len(precos) - 1):\n    estado = dia\n    acao = np.argmax(q_table[estado])  # Escolha a melhor a\u00e7\u00e3o\n\n    if acao == 1 and saldo &gt;= precos[dia]:  # Comprar\n        acao_atual = precos[dia]\n        saldo -= precos[dia]\n    elif acao == 2 and acao_atual is not None:  # Vender\n        saldo += precos[dia]\n        acao_atual = None\n\n    lucros.append(saldo)\n\n# Plotando os pre\u00e7os e os ganhos\nplt.figure(figsize=(10, 5))\nplt.plot(precos, label=\"Pre\u00e7o da A\u00e7\u00e3o\")\nplt.xlabel(\"Dias\")\nplt.ylabel(\"Pre\u00e7o\")\nplt.legend()\nplt.title(\"Simula\u00e7\u00e3o de Pre\u00e7os de A\u00e7\u00f5es\")\nplt.show()\n\nplt.figure(figsize=(10, 5))\nplt.plot(lucros, label=\"Saldo do Agente\")\nplt.xlabel(\"Dias\")\nplt.ylabel(\"Saldo ($)\")\nplt.legend()\nplt.title(\"Evolu\u00e7\u00e3o do Saldo do Agente\")\nplt.show()\n</code></pre> C\u00f3digo 3: Implementa\u00e7\u00e3o em c\u00f3digo do exemplo de um agente que atua no mercado financeiro. Fonte: OPENAI. Assistente Virtual ChatGPT, 2025 <p></p> Imagem 3: Gr\u00e1ficos sobre a simula\u00e7\u00e3o dos pre\u00e7os de a\u00e7\u00f5es e da evolu\u00e7\u00e3o de saldo realizada pelo agente. Fonte: OPENAI. Assistente Virtual ChatGPT, 2025"},{"location":"portifolios/portifolio6/#classificacao-e-regressao","title":"Classifica\u00e7\u00e3o e Regress\u00e3o","text":"<p>Como dito anteriormente, os agentes que aprendem, podem ter sua sa\u00edda de duas formas, essas formas s\u00e3o a classifica\u00e7\u00e3o e a regress\u00e3o.  A classifica\u00e7\u00e3o se refere quando um agente tem uma sa\u00edda com valores finitos, como por exemplo, o agente deve falar qual o clima no momento, sendo que sua sa\u00edda s\u00f3 pode assumir tr\u00eas valores (ensolarado, nublado, chuvoso). E j\u00e1 a regress\u00e3o, o agente deve retornar um n\u00famero como sa\u00edda, por exemplo, ele deve avaliar o custo de uma casa, baseado nos dados de valores das casas vizinhas a que est\u00e1 sendo analizada.    Ao nos aprofundarmos sobre os sistemas de classifica\u00e7\u00e3o e regress\u00e3o, temos alguns detalhes que devem ser entendidos para compreender caracter\u00edsticas sobre como funciona alguns processos pr\u00e9-treinamento do modelo, e p\u00f3s treinamento tamb\u00e9m, nesse sentido podemos citar o pr\u00e9-processamento de dados, a extra\u00e7\u00e3o de caracter\u00edsticas, e alguns problemas derivados do resultado do treinamento que s\u00e3o o overfeeting e o underfeeting.</p>"},{"location":"portifolios/portifolio6/#pre-processamento","title":"Pr\u00e9-processamento","text":"<p>Quando vamos treinar um agente, devemos ter um cuidado com o dataset (conjunto de dados do treinamento) que iremos utilizar para o treinamento, \u00e9 importante explorar o dataset em busca de problemas que podem causar erros ou atrapalhar o nosso treinamento. Alguns do pr\u00e9-processamentos que podemos realizar dentro de um dataset \u00e9 retirar dados incorretos, vazios, ou muito polu\u00eddos (no caso de imagens com muito conte\u00fado), pode ser realizado tamb\u00e9m ajustes de normaliza\u00e7\u00e3o e/ou escalonamento que faz com que os dados fiquem com um padr\u00e3o melhor que ajuda no treinamento e evita erros muito altos. Portanto, existem diversas t\u00e9cnicas de pr\u00e9-processamento que auxiliam o processo de treinamento do agente, aumento o conhecimento do agente sobre o dataset.</p>"},{"location":"portifolios/portifolio6/#extracao-de-caracteristicas","title":"Extra\u00e7\u00e3o de Caracter\u00edsticas","text":"<p>O processo de extra\u00e7\u00e3o de caracter\u00edsticas \u00e9 um processo que transforma os dados \"brutos\" em dados \"lapidados\", ou seja, pegamos dados da forma que chegam pelo dataset, tratamos eles e tornamos eles dados utiliz\u00e1veis pelo modelo. \u00c9 importante entender que o processo de extra\u00e7\u00e3o pode ser realizado tanto pelo desenvolvedor do agente, quanto pelo pr\u00f3prio agente. Quando feito pelo desenvolvedor, se realiza esse processo j\u00e1 citado de forma manual, tranformando os dados em algo melhorado e mais perform\u00e1tico. Quando realizado pelo agente, costuma acontecer quando est\u00e1 sendo utilizado redes neurais ou deep leaning que s\u00e3o modelos mais complexos de treinamento, um exemplo disso \u00e9 quando utilizamos redes convulocionais (CNN) que fazem a extra\u00e7\u00e3o de caracter\u00edsticas de forma independente em imagens por exemplo.</p>"},{"location":"portifolios/portifolio6/#overfitting-e-underfitting","title":"Overfitting e Underfitting","text":"<p>Durante o treinamento, o agente aprende o m\u00e1ximo de caracter\u00edsticas poss\u00edveis e reconhece os padr\u00f5es necess\u00e1rios para a classifica\u00e7\u00e3o de um dado, mas, o aprendizado excessivo de determinada caracter\u00edsticas pode causar problemas ao agente gerando um Overfitting, como aprender muitos ru\u00eddos ou dados irregulares n\u00e3o tratados, que ao final, o modelo se sai perfeito durante os testes do treinamento com uma acur\u00e1cia por volta dos 100%, mas ao tentar utilizar novos dados ele n\u00e3o consegue processar ou classificar. J\u00e1 quando o modelo n\u00e3o consegue entender os dados fornecidos e n\u00e3o percebe os padr\u00f5es dos dados para entend\u00ea-lo, isso \u00e9 um Underfitting, ou seja, o agente n\u00e3o conseguiu aprender nada com o dataset fornecido.</p>"},{"location":"portifolios/portifolio6/#algoritmos-de-aprendizado-supervisionado","title":"Algoritmos de Aprendizado Supervisionado","text":"<p>Nesta se\u00e7\u00e3o iremos analisar alguns algoritmos de aprendizado supervisionado, e entenderemos algumas aplica\u00e7\u00f5es poss\u00edveis para esses modelos.</p>"},{"location":"portifolios/portifolio6/#k-nearest-neighbors","title":"K-Nearest Neighbors","text":"<p>O algoritmo K-Nearest Neighbors \u00e9 um algoritmo que classifica um determinado dado baseado na quantidade de \"vizinhos\" pr\u00f3ximos a ele. Explicando o algoritmo de maneira mais simples, primeiro voc\u00ea escolhe um K que ser\u00e1 a quantidade de \"vizinhos\" que ser\u00e3o analisados, ap\u00f3s isso, o algoritmo ir\u00e1 mapear os dados e verificar os K \"vizinhos\" mais pr\u00f3ximos desse dado (os vizinhos ser\u00e3o os outros dados j\u00e1 classificados), com isso, o algoritmo se utiliza da dist\u00e2ncia euclidiana por exemplo, para encontrar a dist\u00e2ncia entre o dado que est\u00e1 sendo analisado e os K vizinhos mais pr\u00f3ximos, ao final, pensando em um mapeamento onde s\u00f3 existe duas classifica\u00e7\u00f5es 0 e 1 (bin\u00e1ria), se o dado analisado tiver a maior parte dos vizinhos perto dentro da zona de 0, ent\u00e3o ele ser\u00e1 provavelmente 0, se n\u00e3o, ele ser\u00e1 1. </p>"},{"location":"portifolios/portifolio6/#modelos-lineares","title":"Modelos Lineares","text":"<p>Modelos lineares s\u00e3o algoritmos que usa equa\u00e7\u00f5es matem\u00e1ticas para relacionamento de vari\u00e1veis, com o intuito de conseguir prever um resultado baseado em 1 ou mais caracter\u00edsticas dos dados fornecidos, desta forma, ela cria pesos para cada uma das caracter\u00edsticas para no final poder generalizar essa fun\u00e7\u00e3o para outros valores que receber.  Existem dois tipos de modelos lineares, um de regress\u00e3o linear e o outro de regress\u00e3o log\u00edstica. O de regress\u00e3o linear \u00e9 mais utilizado quando queremos prever um valor espec\u00edfico baseado nos dados de entrada. J\u00e1 a regress\u00e3o log\u00edstica \u00e9 mais utilizada quando queremos classificar dados, como no caso citado anteriormente da an\u00e1lise de compradores de uma loja.</p>"},{"location":"portifolios/portifolio6/#classificadores-bayesianos","title":"Classificadores Bayesianos","text":"<p>Os classificadores Bayesianos funcionam basicamente da mesma forma que os modelos lineares de regress\u00e3o log\u00edstica, sua grande diferen\u00e7a \u00e9 que eles se utilizam do teorema de Bayes que ao final ir\u00e1 retornar a probabilidade do dado fornecido pertencer a uma determinada classe. Ele tamb\u00e9m sup\u00f5e que os dados s\u00e3o independentes em seu conjunto, onde muitas vezes isso n\u00e3o \u00e9 realidade, o que pode causar problemas em suas avalia\u00e7\u00f5es. Em contra partida a esse \"problema\" que ele possui, ele \u00e9 muito r\u00e1pido em seu treinamento, principalmente em grandes conjuntos de dados.</p>"},{"location":"portifolios/portifolio6/#redes-neurais-e-aprendizado-profundo","title":"Redes Neurais e Aprendizado Profundo","text":"<p>As redes neurais s\u00e3o um conjunto de modelos e algoritmos que simulam uma rede de neur\u00f4nios assim como no c\u00e9rebro humano, todos as camadas do modelo s\u00e3o interconectadas, sendo todos os neur\u00f4nios sendo conectados a todos os outros neur\u00f4nios da camada anterior e da camada seguinte, isso \u00e9 uma das caracter\u00edsticas que tornam esse tipo de algoritmo extremamente complexo e eficiente.  Um exemplo de rede neural \u00e9 as redes convulocionais, esses tipos de redes costumam criar algo parecido com a imagem 4, onde cada c\u00edrculo representa um neur\u00f4nio e cada neur\u00f4nio \u00e9 conectado a todos da camada anterior e posterior.</p> <p></p> Imagem 4: Gr\u00e1ficos sobre a simula\u00e7\u00e3o dos pre\u00e7os de a\u00e7\u00f5es e da evolu\u00e7\u00e3o de saldo realizada pelo agente. Fonte: Olhar Digital. Dispon\u00edvel em olhardigital.com.br <p></p> <p>Um exemplo que refor\u00e7a o entendimento de uma rede neural convulocional, \u00e9 um algoritmo que recebe a imagem de uma planta e que retorna a doen\u00e7a que ela possui. Esse algoritmo recebe como dado um par de entrada-sa\u00edda, sendo no caso uma imagem e uma label que representa a doen\u00e7a presente na imagem, e ao final retorna a probabilidade das doen\u00e7as que podem estar presentes na planta. A seguir no c\u00f3digo 4 podemos ver um exemplo aplicado deste algoritmo.</p> <pre><code>import tensorflow_datasets as tfds\nfrom math import sqrt\nimport pandas as pd\nimport numpy as np\nfrom numpy import mean\nimport tensorflow as tf\nimport tensorflow_hub as hub\nfrom tensorflow.keras import models, layers\nfrom keras.optimizers.legacy import Adam\nfrom tensorflow.keras.metrics import BinaryAccuracy, TruePositives, TrueNegatives, FalsePositives, FalseNegatives, PrecisionAtRecall, SensitivityAtSpecificity, SpecificityAtSensitivity, Recall\nimport keras\nfrom tensorflow.keras.models import load_model\nfrom keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom google.colab import files\n\nIMAGE_SIZE=128\nBATCH_SIZE=8\nCHANNELS=3\nEPOCHS=30\n\nMETRICS = [keras.metrics.CategoricalAccuracy(name = 'accuracy'),\n           keras.metrics.TruePositives(thresholds = 0.50, name = 'tp'),\n           keras.metrics.TrueNegatives(thresholds = 0.50, name = 'tn'),\n           keras.metrics.FalsePositives(thresholds = 0.50, name = 'fp'),\n           keras.metrics.FalseNegatives(thresholds = 0.50, name = 'fn'),\n           keras.metrics.PrecisionAtRecall(recall = 0.50, name = 'precision'),\n           keras.metrics.SensitivityAtSpecificity(0.50, name = 'sensitivity'),\n           keras.metrics.SpecificityAtSensitivity(sensitivity = 0.50,\n                                                  name = 'specificity'),\n           keras.metrics.Recall(name='recall')]\n\ntf.keras.backend.clear_session() # Limpar o CACHE da se\u00e7\u00e3o\n(ds_train), info = tfds.load('plant_village', split='train', with_info=True)\n\nds = tf.keras.preprocessing.image_dataset_from_directory(\"/root/tensorflow_datasets/downloads/extracted/ZIP.data.mend.com_publ-file_data_tywb_file_d565-c1rDQyRTmE0CqGGXmH53WlQp0NWefMfDW89aj1A0m5D_A/Plant_leave_diseases_dataset_without_augmentation\",\n                                                         shuffle=True,\n                                                         image_size=(IMAGE_SIZE,IMAGE_SIZE),\n                                                         batch_size=BATCH_SIZE)\n\nclass_name = ds.class_names\nds = ds.shuffle(buffer_size=1000, seed=12)\nds = ds.take(int(len(ds)/2))\ntrain_size = 0.8\ntrain_size = int(len(ds)*train_size)\ntrain_ds = ds.take(train_size)\ntest_ds = ds.skip(int(train_size))\ntest_size = int(len(test_ds)*0.5)\nvalidation_ds = test_ds.take(test_size)\ntest_ds = test_ds.skip(test_size)\n\ntrain_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)\nvalidation_ds = validation_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)\ntest_ds = test_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)\n\nresize_rescaling = tf.keras.Sequential([\n    layers.experimental.preprocessing.Resizing(*IMAGE_SIZE),\n    layers.experimental.preprocessing.Rescaling(1.0/255)\n])\ndata_augmentation = tf.keras.Sequential([\n  layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n  layers.experimental.preprocessing.RandomRotation(0.2),\n])\n\nnClasses = 39\n# Aplicando a fun\u00e7\u00e3o de gera\u00e7\u00e3o das varia\u00e7\u00f5es das imagens e ajuste do tamanho e escala das imagens nos conjuntos de treinamento e valida\u00e7\u00e3o\ndef preprocess_image(image, label):\n    image = resize_rescaling(image)\n    image = data_augmentation(image)\n    label = tf.one_hot(tf.cast(label, tf.int32), depth=nClasses)\n    return image, label\n\ntrain_ds = train_ds.map(preprocess_image).prefetch(buffer_size=tf.data.AUTOTUNE)\n\nvalidation_ds = validation_ds.map(\n    lambda x, y: (resize_rescaling(x), tf.one_hot(tf.cast(y, tf.int32), depth=nClasses))\n).prefetch(buffer_size=tf.data.AUTOTUNE)\n\ntest_ds = test_ds.map(\n    lambda x, y: (resize_rescaling(x), tf.one_hot(tf.cast(y, tf.int32), depth=nClasses))\n).prefetch(buffer_size=tf.data.AUTOTUNE)\n\ninputShape = (IMAGE_SIZE, IMAGE_SIZE, CHANNELS)\n\n# Defini\u00e7\u00e3o da arquitetura do modelo\nmodel = models.Sequential()\n\nmodel.add(layers.Conv2D(filters = 64,\n                kernel_size = (3, 3),\n                input_shape = inputShape,\n                activation = 'relu'))\n\nmodel.add(layers.BatchNormalization()) # Polimento dos dados usando normaliza\u00e7\u00e3o\n\nmodel.add(layers.MaxPooling2D(pool_size = (2, 2))) # reduz a dimens\u00e3o dos mapas de caracter\u00edsticas\n\nmodel.add(layers.Conv2D(filters = 256,\n                kernel_size = (3, 3),\n                activation = 'relu'))\n\nmodel.add(layers.Conv2D(filters = 256,\n                kernel_size = (3, 3),\n                activation = 'relu'))\n\nmodel.add(layers.BatchNormalization())\n\nmodel.add(layers.MaxPooling2D(pool_size = (2, 2)))\n# Fim da alimenta\u00e7\u00e3o do modelo e extra\u00e7\u00e3o de caracter\u00edsticas\n\n# \u00cdnicio do treinamento do modelo\nmodel.add(layers.Flatten()) #achatamento para a pr\u00f3xima camada para encontrar os melhores pesos\n\nmodel.add(layers.Dense(units = 256,\n                activation = 'relu'))\n\nmodel.add(layers.Dropout(0.2))\n\nmodel.add(layers.Dense(units = 256,\n                activation = 'relu'))\n\nmodel.add(layers.Dropout(0.2))\n\nmodel.add(layers.Dense(units = 128,\n                activation = 'relu'))\n\nmodel.add(layers.Dense(units = nClasses,\n                activation = 'softmax'))\n\noptimizer = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=0.1, decay=0.0)\n\n# Compila\u00e7\u00e3o do Modelo\nmodel.compile(loss = keras.losses.categorical_crossentropy,\n              optimizer = optimizer,\n              metrics = METRICS)\n\nlearning_rate = keras.callbacks.ReduceLROnPlateau(monitor = 'accuracy',\n                                  factor = 0.2, # a taxa de aprendizado ser\u00e1 multiplicada por 0.2 sempre que as condi\u00e7\u00f5es forem satisfeitas\n                                  patience = 1, # limite de \u00e9pocas que a taxa de acur\u00e1cio pode n\u00e3o melhorar, caso ultrapasse, a taxa de aprendizado \u00e9 reduzida\n                                  min_lr = 0.000001, # Limite da taxa de aprendizado, ela n\u00e3o ir\u00e1 diminuir mais que isso\n                                  verbose = 1) # usado para imprimir a mensagem que a taxa foi modificada\n\ntf.keras.backend.clear_session()\n\nhist = model.fit(train_ds,\n                 epochs = EPOCHS,\n                 batch_size=BATCH_SIZE,\n                 validation_data = validation_ds,\n                 validation_steps = 25,\n                 callbacks = [learning_rate],\n                 verbose = 1)\n</code></pre> C\u00f3digo 4: Implementa\u00e7\u00e3o em c\u00f3digo do exemplo de rede neural para identifica\u00e7\u00e3o de doen\u00e7as em plantas. Fonte: Autor <p></p> <p>Portanto, se observamos o c\u00f3digo 4 fica claro todas as etapas j\u00e1 citadas de pr\u00e9-processamento de dados, observamos que o pr\u00f3prio algoritmo realiza a extra\u00e7\u00e3o de caracter\u00edsticas, e existem v\u00e1rias outras t\u00e9cnicas inclusas para melhor aprendizado do modelo.</p>"},{"location":"portifolios/portifolio6/#explainable-artificial-intelligence-xai","title":"Explainable Artificial Intelligence (XAI)","text":"<p>O Explanaible Artificial Intelligence (XAI) \u00e9 um conjunto de m\u00e9todo e processos desenvolvidos para que os usu\u00e1rios humanos consigam entender e confiar nos resultados e sa\u00eddas fornecidos por agentes e algoritmos (IBM, 2025).  Um dos principais focos do XAI \u00e9 permitir que os usu\u00e1rios humanos entendam como funciona o processo de decis\u00f5es de um modelo, j\u00e1 que as IA's tradicionais n\u00e3o mostram isso a n\u00f3s. Essa transpar\u00eancia ajuda a construir uma confian\u00e7a, mitigar riscos e garantir a responsabilidades desses modelos. Essa explicabilidade que a XAI prov\u00ea aos usu\u00e1rios, ajuda a identificar vieses, desvios e riscos dos modelos utilizados, garantindo a escalabilidade e a connfiabilidade.</p>"},{"location":"portifolios/portifolio6/#algoritmos-de-aprendizado-nao-supervisionado","title":"Algoritmos de Aprendizado N\u00e3o Supervisionado","text":"<p>Nesta se\u00e7\u00e3o iremos discutir e conhecer um pouco mais sobre alguns dos principais algoritmos de aprendizagem n\u00e3o supervisionado.</p>"},{"location":"portifolios/portifolio6/#k-means-clustering","title":"K-means Clustering","text":"<p>O K-means Clustering \u00e9 utilizado como um modelo classificat\u00f3rio que tem como objetivo separar em K grupos (clusters) os dados que foram fornecidos, sendo que o valor de K \u00e9 definido pelo desenvolvedor do agente. Ao iniciar o algoritmo seleciona K pontos de forma aleat\u00f3ria dentro dos conjuntos para que sejam suas posi\u00e7\u00f5es centrais, ap\u00f3s isso o algoritmo usa alguma fun\u00e7\u00e3o matem\u00e1tica como a dist\u00e2ncia Euclidiana para calcular o centro real de cada grupo, e com isso ele consegue separar da forma correta os dados em seus respectivos grupos. A seguir podemos ver um exemplo do algoritmo K-means no c\u00f3digo 5.</p> <pre><code>import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.cluster import KMeans\n\n# Gerando um conjunto de dados de exemplo\nnp.random.seed(42)\nX = np.random.rand(100, 2) * 10  # 100 pontos com 2 caracter\u00edsticas\n\n# Aplicando K-means com K=3\nkmeans = KMeans(n_clusters=3, random_state=42)\nkmeans.fit(X)\nlabels = kmeans.labels_\ncentroids = kmeans.cluster_centers_\n\n# Plotando os clusters\nplt.scatter(X[:, 0], X[:, 1], c=labels, cmap='viridis', marker='o', edgecolors='k')\nplt.scatter(centroids[:, 0], centroids[:, 1], c='red', marker='X', s=200, label=\"Centr\u00f3ides\")\nplt.title(\"Agrupamento com K-means\")\nplt.xlabel(\"Caracter\u00edstica 1\")\nplt.ylabel(\"Caracter\u00edstica 2\")\nplt.legend()\nplt.show()\n</code></pre> C\u00f3digo 5: Implementa\u00e7\u00e3o em c\u00f3digo do exemplo do algoritmo K-means Clustering com dados fict\u00edcios. Fonte: OPENAI. Assistente Virtual ChatGPT, 2025"},{"location":"portifolios/portifolio6/#self-organized-maps","title":"Self-organized Maps","text":"<p>O algoritmo Self-organized Maps, diferente do K-means, se baseia em redes neurais artificiais, e seu principal objetivo \u00e9 mapear os padr\u00f5es para agrup\u00e1-los, e sua sa\u00edda \u00e9 um mapa bidimensional. Ele extrai suas caracter\u00edsticas de forma autom\u00e1tica e corrije os pesos de sua fun\u00e7\u00e3o com o decorrer do processo de treinamento, onde esse processo termina ap\u00f3s se tornarem o mais eficiente poss\u00edvel, e ap\u00f3s agrupar os padr\u00f5es similares. No c\u00f3digo 6 podemos ver a aplica\u00e7\u00e3o do algoritmo utilizando dados fict\u00edcios.</p> <pre><code>import numpy as np\nimport matplotlib.pyplot as plt\nfrom minisom import MiniSom\n\n# Gerando dados sint\u00e9ticos\nnp.random.seed(42)\nX = np.random.rand(200, 3)  # 200 amostras com 3 caracter\u00edsticas\n\n# Criando e treinando a rede SOM (10x10)\nsom = MiniSom(10, 10, 3, sigma=1.0, learning_rate=0.5)\nsom.random_weights_init(X)\nsom.train_random(X, 1000)\n\n# Criando um mapa de ativa\u00e7\u00e3o dos neur\u00f4nios\nplt.figure(figsize=(8, 6))\nfor x, y in X:\n    w = som.winner([x, y])  # Encontra o neur\u00f4nio vencedor\n    plt.plot(w[0] + 0.5, w[1] + 0.5, 'ro', markersize=5)\n\nplt.xlim(0, som.get_weights().shape[0])\nplt.ylim(0, som.get_weights().shape[1])\nplt.title(\"Mapa Auto-organiz\u00e1vel (SOM)\")\nplt.show()\n</code></pre> C\u00f3digo 6: Implementa\u00e7\u00e3o em c\u00f3digo do exemplo do algoritmo Self-organized Maps com dados fict\u00edcios. Fonte: OPENAI. Assistente Virtual ChatGPT, 2025"},{"location":"portifolios/portifolio6/#algoritmos-de-aprendizado-por-reforco","title":"Algoritmos de Aprendizado por Refor\u00e7o","text":"<p>Nesta se\u00e7\u00e3o iremos explorar algoritmos de aprendizado por refor\u00e7o, entendendo suas caracter\u00edsticas e entendendo seu funcionamento.</p>"},{"location":"portifolios/portifolio6/#q-leaning","title":"Q-Leaning","text":"<p>O Q-Leaning \u00e9 um algoritmo de aprendizado por refor\u00e7o baseado em valores, onde \u00e9 usado para ensinar agentes a tomar decis\u00f5es independente do ambiente inserido, com isso ele faz com que o agente aprenda de qualquer maneira o melhor conjunto de a\u00e7\u00f5es poss\u00edveis para se utilizar no ambiente, independente da estrat\u00e9gia fornecida durante o treinamento, e mapeando no Q-Table (Tabela que representa as a\u00e7\u00f5es poss\u00edveis). Um exemplo de id\u00e9ia de agente que \u00e9 muito semelhante ao que o algoritmo prop\u00f5e \u00e9 o Mundo de Wumpus, onde um agente deve se adaptar ao ambiente baseado no que ele tem percep\u00e7\u00e3o no momento. A seguir podemos ver a aplica\u00e7\u00e3o do algoritmo no Mundo de Wumpus no c\u00f3digo 7.</p> <pre><code>import numpy as np\nimport random\n\n# Defini\u00e7\u00e3o do ambiente do Mundo de Wumpus\ngrid_size = 4\nactions = ['up', 'down', 'left', 'right']\nn_actions = len(actions)\nn_states = grid_size * grid_size\n\n# Defini\u00e7\u00e3o das recompensas do ambiente\nreward_map = np.full((grid_size, grid_size), -1)  # Penalidade por cada movimento\nreward_map[0, 3] = 100  # Ouro\nreward_map[1, 3] = -100  # Wumpus\nreward_map[2, 2] = -100  # Po\u00e7o\nreward_map[3, 3] = -100  # Po\u00e7o\n\n# Inicializa a Q-Table\nQ_table = np.zeros((n_states, n_actions))\n\n# Hiperpar\u00e2metros\nalpha = 0.1  # Taxa de aprendizado\ngamma = 0.9  # Fator de desconto\nepsilon = 1.0  # Probabilidade de explora\u00e7\u00e3o\nepsilon_decay = 0.99\nepsilon_min = 0.01\nnum_episodes = 5000  # N\u00famero de rodadas de treinamento\n\n# Fun\u00e7\u00e3o para converter posi\u00e7\u00e3o no grid para estado\ndef state_from_position(row, col):\n    return row * grid_size + col\n\n# Fun\u00e7\u00e3o para obter a nova posi\u00e7\u00e3o ap\u00f3s uma a\u00e7\u00e3o\ndef get_new_position(row, col, action):\n    if action == 'up' and row &gt; 0:\n        row -= 1\n    elif action == 'down' and row &lt; grid_size - 1:\n        row += 1\n    elif action == 'left' and col &gt; 0:\n        col -= 1\n    elif action == 'right' and col &lt; grid_size - 1:\n        col += 1\n    return row, col\n\n# Treinamento com Q-Learning\nfor episode in range(num_episodes):\n    row, col = 3, 0  # Come\u00e7a no canto inferior esquerdo\n    done = False\n\n    while not done:\n        state = state_from_position(row, col)\n\n        # Explora\u00e7\u00e3o x Explora\u00e7\u00e3o\n        if np.random.rand() &lt; epsilon:\n            action_index = np.random.choice(n_actions)  # Explora\u00e7\u00e3o\n        else:\n            action_index = np.argmax(Q_table[state, :])  # Explora\u00e7\u00e3o\n\n        action = actions[action_index]\n        new_row, new_col = get_new_position(row, col, action)\n        new_state = state_from_position(new_row, new_col)\n\n        # Obt\u00e9m recompensa\n        reward = reward_map[new_row, new_col]\n\n        # Atualiza Q-Table\n        Q_table[state, action_index] = Q_table[state, action_index] + alpha * (\n            reward + gamma * np.max(Q_table[new_state, :]) - Q_table[state, action_index]\n        )\n\n        row, col = new_row, new_col\n\n        # Se encontrar o ouro ou cair em um po\u00e7o/Wumpus, encerra o epis\u00f3dio\n        if reward == 100 or reward == -100:\n            done = True\n\n    # Redu\u00e7\u00e3o do epsilon para diminuir a explora\u00e7\u00e3o ao longo do tempo\n    epsilon = max(epsilon * epsilon_decay, epsilon_min)\n\n# Testando o agente treinado\nrow, col = 3, 0  # Posi\u00e7\u00e3o inicial do agente\nprint(\"\\nCaminho aprendido pelo agente:\\n\")\n\nwhile True:\n    state = state_from_position(row, col)\n    action_index = np.argmax(Q_table[state, :])\n    action = actions[action_index]\n    print(f\"Agente est\u00e1 em ({row}, {col}), a\u00e7\u00e3o escolhida: {action}\")\n\n    row, col = get_new_position(row, col, action)\n\n    if reward_map[row, col] == 100:\n        print(f\"Agente encontrou o ouro em ({row}, {col})! \")\n        break\n    elif reward_map[row, col] == -100:\n        print(f\"Agente morreu no po\u00e7o ou pelo Wumpus em ({row}, {col})! \")\n        break\n</code></pre> C\u00f3digo 7: Implementa\u00e7\u00e3o em c\u00f3digo do exemplo do algoritmo Q-Leaning no Mundo de Wumpus. Fonte: OPENAI. Assistente Virtual ChatGPT, 2025"},{"location":"portifolios/portifolio6/#deep-q-network","title":"Deep Q-Network","text":"<p>O Depp Q-Network (DQN) \u00e9 uma vers\u00e3o aprimorada do Q-Learning que se utiliza de redes neurais ao inv\u00e9s de uma Q-Table para estipular suas a\u00e7\u00f5es, e com isso o tornando mais eficiente para ambientes complexos e cont\u00ednuos. Podemos ver um exemplo da aplica\u00e7\u00e3o do DQN em um jogo chamado CartPole, onde o agente tem que equilibrar um poste sobre um carrinho, podemos ver sua aplica\u00e7\u00e3o no c\u00f3digo 8.</p> <pre><code>import gym\nimport numpy as np\nimport random\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom collections import deque\n\n# Criando o ambiente CartPole\nenv = gym.make(\"CartPole-v1\")\n\n# Defini\u00e7\u00e3o da rede neural para o agente DQN\nclass DQN(nn.Module):\n    def __init__(self, state_size, action_size):\n        super(DQN, self).__init__()\n        self.fc1 = nn.Linear(state_size, 24)\n        self.fc2 = nn.Linear(24, 24)\n        self.fc3 = nn.Linear(24, action_size)\n\n    def forward(self, x):\n        x = torch.relu(self.fc1(x))\n        x = torch.relu(self.fc2(x))\n        return self.fc3(x)\n\n# Hiperpar\u00e2metros\nstate_size = env.observation_space.shape[0]  # 4 estados (posi\u00e7\u00e3o, velocidade, \u00e2ngulo do poste, velocidade angular)\naction_size = env.action_space.n  # 2 a\u00e7\u00f5es (esquerda e direita)\nlearning_rate = 0.001\ngamma = 0.99  # Fator de desconto\nepsilon = 1.0  # Explora\u00e7\u00e3o inicial\nepsilon_min = 0.01\nepsilon_decay = 0.995\nbatch_size = 32\nmemory = deque(maxlen=2000)  # Mem\u00f3ria para replay\nmodel = DQN(state_size, action_size)  # Criando o modelo DQN\noptimizer = optim.Adam(model.parameters(), lr=learning_rate)\nloss_fn = nn.MSELoss()\n\n# Fun\u00e7\u00e3o para escolher a\u00e7\u00e3o (Explora\u00e7\u00e3o x Explora\u00e7\u00e3o)\ndef choose_action(state):\n    if np.random.rand() &lt;= epsilon:\n        return random.choice([0, 1])  # Explora\u00e7\u00e3o\n    with torch.no_grad():\n        return torch.argmax(model(torch.FloatTensor(state))).item()  # Explora\u00e7\u00e3o\n\n# Treinamento do DQN\ndef train():\n    global epsilon\n    if len(memory) &lt; batch_size:\n        return\n\n    batch = random.sample(memory, batch_size)\n    states, actions, rewards, next_states, dones = zip(*batch)\n\n    states = torch.FloatTensor(states)\n    actions = torch.LongTensor(actions)\n    rewards = torch.FloatTensor(rewards)\n    next_states = torch.FloatTensor(next_states)\n    dones = torch.FloatTensor(dones)\n\n    # Previs\u00e3o de valores Q atuais\n    q_values = model(states).gather(1, actions.unsqueeze(1)).squeeze(1)\n\n    # Previs\u00e3o de valores Q futuros\n    with torch.no_grad():\n        max_next_q_values = model(next_states).max(1)[0]\n        targets = rewards + gamma * max_next_q_values * (1 - dones)\n\n    loss = loss_fn(q_values, targets)\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n\n    # Redu\u00e7\u00e3o do epsilon\n    if epsilon &gt; epsilon_min:\n        epsilon *= epsilon_decay\n\n# Loop de treinamento\nnum_episodes = 500\nfor episode in range(num_episodes):\n    state = env.reset()[0]\n    total_reward = 0\n\n    while True:\n        action = choose_action(state)\n        next_state, reward, done, _, _ = env.step(action)\n        memory.append((state, action, reward, next_state, done))\n        state = next_state\n        total_reward += reward\n\n        if done:\n            print(f\" Epis\u00f3dio {episode + 1}, Recompensa: {total_reward}\")\n            break\n\n        train()\n\n</code></pre> C\u00f3digo 8: Implementa\u00e7\u00e3o em c\u00f3digo do exemplo do algoritmo DQN no jogo CartPole. Fonte: OPENAI. Assistente Virtual ChatGPT, 2025"},{"location":"portifolios/portifolio6/#conclusao","title":"Conclus\u00e3o","text":"<p>Portanto, ap\u00f3s explorar os fundamentos do aprendizado de agentes, passando por suas motiva\u00e7\u00f5es at\u00e9 aos exemplos de utiliza\u00e7\u00f5es reais, vimos que agentes que aprendem podem solucionar centenas de problemas complexos existentes no mundo atual, al\u00e9m de abrir oportunidades de resolver problemas ainda n\u00e3o explorados. Esses modelos de agentes s\u00e3o extremamente importantes para o estudo e evolu\u00e7\u00e3o dos futuros modelos de IA's, j\u00e1 que abrem portas para resolverem problemas ainda mais complexos dos que existem atualmente. </p>"},{"location":"portifolios/portifolio6/#referencias","title":"Refer\u00eancias","text":"<p>[1] RUSSELL, Stuart; NORVIG, Peter. Intelig\u00eancia Artificial: Uma Abordagem Moderna \u2013 3\u00aa edi\u00e7\u00e3o. [2] OPENAI. Assistente Virtual ChatGPT. Respostas geradas com base em intelig\u00eancia artificial. Dispon\u00edvel em: https://openai.com. Acesso em: 04 dez. 2025. [3] IBM. (n.d.). Intelig\u00eancia Artificial Explic\u00e1vel (XAI). IBM. Recuperado em 17 de fevereiro de 2025, de https://www.ibm.com/br-pt/topics/explainable-ai#:~:text=Intelig%C3%AAncia%20artificial%20explic%C3%A1vel%20%28XAI%29%20%C3%A9%20um%20conjunto%20de,sa%C3%ADdas%20criadas%20por%20algoritmos%20de%20aprendizado%20de%20m%C3%A1quina.</p>"}]}